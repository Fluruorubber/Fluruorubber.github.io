<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>现代艺术与设计史3</title>
    <url>/2020/04/17/%E7%8E%B0%E4%BB%A3%E8%89%BA%E6%9C%AF%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8F%B23/</url>
    <content><![CDATA[<p>现实主义：<br>巴比松画派；<br>印象主义，后印象派；</p>
<a id="more"></a>
<p><img src="https://i.loli.net/2020/04/20/rWRn1etDlfMTH6L.png" alt="2020-04-16 142902.png" style="zoom: 50%;"><br>浪漫主义 vs 印象主义：浪漫主义动荡的美学，暴力美学，不做太多的美学修饰，影响了印象派画瞬间的光感，印象派用色更加大胆奔放。<br>浪漫主义 vs 现实主义：浪漫主义是同时代发生的；现实主义是亲眼看见的。</p>
<hr>
<h4 id="现实主义"><a href="#现实主义" class="headerlink" title="现实主义"></a>现实主义</h4><h5 id="库尔贝-法国"><a href="#库尔贝-法国" class="headerlink" title="库尔贝 (法国)"></a>库尔贝 (法国)</h5><p>&emsp; 现实主义：库尔贝，gustave courbet，法国，1819-1877<br>&emsp; 学院主义：布格罗，william Adolphe bouguereau，1825-1905<br>&emsp; 现实主义认为学院主义造作，学院主义觉得现实主义丑。(库尔贝在当时是被排斥的，入选不了官方的沙龙；在沙龙对面搭棚子，自称现实主义库尔贝，对抗官方)<br><img src="https://i.loli.net/2020/04/20/iDwyk4NZWYPJSdV.png" alt="截屏2020-04-16下午2.38.15.png"><br>左侧是现实主义库尔贝，右侧是古典主义布格罗。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/72/35977.jpg" alt="库尔贝"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/61/30487.jpg" alt="布格罗"></div></div><div class="group-picture-row"></div></div></div></p>
<p><img src="https://i.loli.net/2020/04/20/iW62EIO7uk4MnJ5.png" alt="库尔贝.png"></p>
<hr>
<h4 id="巴比松画派"><a href="#巴比松画派" class="headerlink" title="巴比松画派"></a>巴比松画派</h4><p>审美和现实主义差不多，也是画亲眼所见的东西。巴比松是法国的一个郊区，写生，务农，画画等。以前都是室内速写，巴比松是室内+室外，影响了印象主义的风景写生。不是采风，是生活在那里。</p>
<h5 id="米勒-法国"><a href="#米勒-法国" class="headerlink" title="米勒 (法国)"></a>米勒 (法国)</h5><p>&emsp; 米勒：Jean-Francois Miller，法国，1814-1875. 现实主义，巴比松画派.<br>&emsp; 被叫做农民画家，因为经常画农民。画有一种宗教的美感，劳作时候内心的平静感。<br><img src="https://i.loli.net/2020/04/20/JBKDLaxwkgsjOvq.jpg" alt="米勒.jpg" style="zoom: 67%;"></p>
<h5 id="柯罗-法国"><a href="#柯罗-法国" class="headerlink" title="柯罗 (法国)"></a>柯罗 (法国)</h5><p>&emsp; 柯罗：jean baptiste camille corot，1796-1875，巴比松画派<br>&emsp; 对印象主义的影响更多，已经有了朦胧的光感，瞬间美感的味道，与古典主义的永恒美不同.<br><img src="https://i.loli.net/2020/04/20/Vp5NIhDa9nOWFoH.png" alt="柯罗1.png" style="zoom: 50%;"><br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/20/YrgLNKVW23Cb6wM.jpg" alt="柯罗2.jpg"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/20/omdKDWGkpZqNjMX.jpg" alt="柯罗3.jpg"></div></div><div class="group-picture-row"></div></div></div></p>
<hr>
<h4 id="印象主义"><a href="#印象主义" class="headerlink" title="印象主义"></a>印象主义</h4><p>&emsp; 主义 vs 派：流派的产生带有偶然性自发性(最开始印象派是贬义的说法，当时一个记者嘲讽莫奈靠印象画画)；主义是指已经被历史认可，是对后世产生了影响的.<br>&emsp; 题材：不画宏大的题材，画火车站朋友聚会等身边发生的事物。<br>&emsp; 古典主义时期用的都是色粉，买矿石请人研磨后调制，放在罐子里，颜色种类也不多（十种左右，靠调和来调颜色）。古典主义削弱色彩的偶然性和主观性，倾向于线条造型等元素，与当时颜料不丰富也有关系。印象派的时候习惯颜料已经产生了；而且这个时候摄影术也已经产生了。<br>&emsp; 印象派色彩、光影很丰富，真实的。<br><img src="https://i.loli.net/2020/04/22/Hx1JVh6yQvK8TPq.png" alt="截屏2020-04-16下午2.45.27.png"></p>
<h5 id="莫奈-法国"><a href="#莫奈-法国" class="headerlink" title="莫奈 (法国)"></a>莫奈 (法国)</h5><p>&emsp; 画史很长，早期作品还是属于素描那种黑白，逐渐改变；受到日本浮世绘影响很大。<br>日出：<br>&emsp; 落选者沙龙。那个时候还喜欢安格尔那种写实人像，觉得莫奈这类人马马虎虎不认真画画。看局部，有中国水墨画的味道。<br><img src="https://i.loli.net/2020/04/22/kv1mfe83MPQhJdg.jpg" alt="日出.jpg"><br><img src="https://i.loli.net/2020/04/22/nvFJZDio4z6cXtB.png" alt="日出细节.png"><br>&emsp; 印象主义是真实的，客观的，认为古典主义是不真实的。像实验一样，在不同的时间段去画。<br><img src="https://i.loli.net/2020/04/22/z5Ebut3Lrad2MiW.png" alt="印象主义.png"></p>
<p><img src="https://s1.ax1x.com/2020/04/19/JMM29K.png" alt="莫奈不同时间段"></p>
<p><img src="https://i.loli.net/2020/04/22/4Rpw5WodjQNB18r.png" alt="印象主义写生.png"><br>&emsp; 阳光是偏黄的，暗部是蓝紫色的。<br><img src="https://i.loli.net/2020/04/22/ExGOi68t9PYmfVz.png" alt="截屏2020-04-16下午2.55.11.png"><br>&emsp; 色晕，流动的小笔触，其实是真实存在的。<br><img src="https://i.loli.net/2020/04/22/IyzqlWS7nar6TRB.png" alt="色晕.png"><br>&emsp; 笔触 碎笔<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/97/48228.jpg" alt="埃特勒塔西部的大岩门.png" style="zoom:67%;"><br>&emsp; 红和绿的对比色，但是在中间加了蓝色，用来调和这种冲突。也是碎笔笔触。逐渐开始弱化造型，(包括很多睡莲图等等)，但不算抽象主义，因为还是从具体的实物演化出来的。<br><img src="https://s1.ax1x.com/2020/04/22/JYvJSJ.png" alt="莫奈" style="zoom:67%;"></p>
<h5 id="马奈-法国"><a href="#马奈-法国" class="headerlink" title="马奈 (法国)"></a>马奈 (法国)</h5><p>&emsp; 是一个有点矛盾的人。并不坚持莫奈那样外光写生，不承认自己是印象派但是不排斥印象派；进过沙龙想进，但是大多数时候还是被退稿。<br>&emsp; 特点：平面化，把立体隐藏在色块中；大平光。古典主义大都是45度倾斜光；马奈大平光，虽然看起来有点粗糙，但是仍然很精准准确，马奈其本身古典主义塑形能力很强。<br>&emsp; 从主题上来讲不符合当时社会的标准，因此经常落选沙龙。<br><img src="https://s1.ax1x.com/2020/04/22/JYx74O.jpg" alt="草地情人"><br>&emsp; 大平光对比图：<br><img src="https://i.loli.net/2020/04/22/HoVSnN7v3kExmIP.png" alt="马奈对比图.png"><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47596.jpg" alt="大平光.jpg"><br>&emsp; 速写很精准<br><img src="https://s1.ax1x.com/2020/04/22/JYxbCD.jpg" alt="马奈速写手"><br>&emsp; 平面化，色块化：<br><img src="https://i.loli.net/2020/04/22/M7BLhUAl5irRWOV.jpg" alt="色块化.jpg" style="zoom:50%;"><br>&emsp; 脸上甚至画出了紫外线的感觉；手，造型很准<br><img src="https://i.loli.net/2020/04/22/aZgbcxRM3d4ovTL.jpg" alt="在花房里.jpg"></p>
<h5 id="西斯莱"><a href="#西斯莱" class="headerlink" title="西斯莱"></a>西斯莱</h5><p>&emsp; 景物很简单，通常天空就站到画面的2/3；和莫奈相比，灰一点、大一点。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/22/B1fLGZcTgNQH3yb.jpg" alt="西斯莱.jpg"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/22/8zgXpZRH5YKFtMh.jpg" alt="西斯莱2.jpg"></div></div><div class="group-picture-row"></div></div></div></p>
<h5 id="雷诺阿"><a href="#雷诺阿" class="headerlink" title="雷诺阿"></a>雷诺阿</h5><p>&emsp; 光斑下的裸女对比图，影影绰绰。左侧是古典主义布格罗。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/61/30487.jpg" alt="布格罗" style="zoom:50%;"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/88/43538.jpg" alt="阳光下的裸女" style="zoom:67%;"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/88/43509.jpg" alt="浴女" style="zoom:67%;"></div></div><div class="group-picture-row"></div></div></div><br>&emsp; 经常画舞池，一堆人跳舞，注意看光影。虽然那个时候普法战争比较惨烈，但是在印象派中看不到战争的动荡，印象派都画身边的悠闲与美好。<br><img src="https://i.loli.net/2020/04/22/S7vtcV4wh3fXe8D.jpg" alt="43539.jpg"><br>&emsp; 对比图，左边是鲁贝斯画的，右边是雷诺阿画的<br><img src="https://i.loli.net/2020/04/22/TLkDZ1E7UKw5pF6.png" alt="古典主义和雷诺阿.png"></p>
<h5 id="德加"><a href="#德加" class="headerlink" title="德加"></a>德加</h5><p>&emsp; 虽然是莫奈的好朋友，但是反对外光写生，虽然也写生但是强调要在工作室再创作加工。虽然不外光写生，但是色彩是印象主义的。</p>
<p>&emsp; 舞女是经常创作的题材。也做雕塑。<br><img src="https://i.loli.net/2020/04/22/4BxYImckVlvqRyQ.jpg" alt="芭蕾舞者.jpg" style="zoom:50%;"><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/28/13526.jpg" alt="芭蕾舞排练.jpg" style="zoom:50%;"><br><img src="https://i.loli.net/2020/04/22/2UiId1aGJmFj3YC.png" alt="2020-04-16 151645.png"><br><img src="https://i.loli.net/2020/04/22/WGzMJvxfBwDRcUm.png" alt="德加.png"></p>
<h5 id="劳特累克"><a href="#劳特累克" class="headerlink" title="劳特累克"></a>劳特累克</h5><p>比上面的要小一代人，和德加一样有许多色粉创作，也是贵族，被希望寄托家业，但是两次骨折，变成了侏儒，很难成为上层资产阶级大银行家，后来就住在了红磨坊中，画一些三流演员妓女的生活状态，没有丑化的意思，这些人都算是他的朋友。</p>
<p><img src="https://i.loli.net/2020/04/22/b62w9aVvCdpykh3.png" alt="劳特累克.png"></p>
<h5 id="巴齐耶"><a href="#巴齐耶" class="headerlink" title="巴齐耶"></a>巴齐耶</h5><h5 id="毕沙罗"><a href="#毕沙罗" class="headerlink" title="毕沙罗"></a>毕沙罗</h5><p>印象主义最长者，1830-1903。经常作为长者来调节印象派内部的一些矛盾什么的。点彩主义，小色点。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/65/32410.jpg" alt="林中浴女" style="zoom:50%;"><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/65/32426.jpg" alt="bishaluo" style="zoom:50%;"></p>
<h5 id="修拉"><a href="#修拉" class="headerlink" title="修拉"></a>修拉</h5><p>真的的点彩派。1859-1891。不喜欢用助手，三十几岁就去世了，作画操劳过度。画的尺寸大工作量也很大，大尺幅，每一个都是小色点。<br><img src="https://i.loli.net/2020/04/22/BSLxF9mYHrIKWea.jpg" alt="大碗岛的星.jpg" style="zoom:50%;"><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/97/48139.jpg" alt="安涅尔浴场" style="zoom:50%;"></p>
<h5 id="希涅克"><a href="#希涅克" class="headerlink" title="希涅克"></a>希涅克</h5><p>修拉后继者，本身是水手，会画一些船之类的题材。比修拉颜色更纯更鲜艳（认为所有颜色都是可以由纯色点构成，不喜欢调和）(有一点机械化)<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/101/50398.jpg" alt="西涅克"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/101/50400.jpg" alt="绿色的海洋"></div></div><div class="group-picture-row"></div></div></div><br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/101/50392.jpg" alt="西涅克"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/101/50441.jpg" alt="西涅克"></div></div><div class="group-picture-row"></div></div></div></p>
<hr>
<h4 id="后印象派与后印象主义"><a href="#后印象派与后印象主义" class="headerlink" title="后印象派与后印象主义"></a>后印象派与后印象主义</h4><ul>
<li>后印象派：梵高，塞尚，高更</li>
<li>新印象主义 点彩派：修拉，西涅克</li>
</ul>
<h5 id="梵高-荷兰人"><a href="#梵高-荷兰人" class="headerlink" title="梵高 (荷兰人)"></a>梵高 (荷兰人)</h5><p>&emsp; 只有梵高是荷兰人，其他都是法国人。但是梵高后来也在巴黎闯荡，当时的艺术家们其实是通过梵高的弟弟认识梵高的。梵高的弟弟能卖画，认识高更，从而把梵高带进了艺术圈。(高更和修拉的话差异虽然很大，但是高更认为修拉的画是唯一能和他相比的)<br>&emsp; 梵高是半路学画，勤奋，天才。风格形成时间很短，中间有摇摆，去世前一两年才形成。穷，没有模特，于是画了很多自画像。<br>&emsp; 早期模仿古典主义，但是画不像(画不细致，性格笔触等等)<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/26/lohQMV851INmwWk.jpg" alt="梵高自画像1.jpeg"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/26/teO8bQFWxcplCKE.jpg" alt="梵高自画像1.jpg"></div></div><div class="group-picture-row"></div></div></div><br>&emsp; 后来收到点彩主义的影响，开始模仿点彩主义<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/10/4966.jpg" alt="梵高自画像2"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47906.jpg" alt="梵高自画像2"></div></div><div class="group-picture-row"></div></div></div><br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/10/4965.jpg" alt="梵高自画像3"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/10/4964.jpg" alt="梵高自画像3"></div></div><div class="group-picture-row"></div></div></div><br>&emsp; 平面化<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/97/48006.jpg" alt="梵高自画像4"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/26/k7CSKHqtnWrwXe9.jpg" alt="梵高自画像4.jpg"></div></div><div class="group-picture-row"></div></div></div><br>&emsp; 风格开始形成，旋转性的出来了，是设计出来的颜色而不是眼睛看到的颜色。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/97/48037.jpg" alt="自画像风格" style="zoom: 50%;"><br>坦圭先生：<br>&emsp; 1888年以后开始逐渐形成自己的色彩风格。有一点机械化的笔触，平面化逐渐形成，但那个时候还没有形成转圈。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47914.jpg" alt="坦圭先生" style="zoom:50%;"></p>
<p>&emsp; 不用古典主义的虚实，用符号来表示，首先出现在风景的速写里面。还有一大特点是画面的增厚。<br>花园花开：<br>&emsp; 1888年，在点彩派的影响下，逐渐符号化。<br><img src="http://www.youhuaaa.com/UploadFiles/images/
Painting_Pic_Big/96/47930.jpg" alt="花园花开" style="zoom:50%;"><br>犁过的田地：<br>&emsp;1888年。画面增厚。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/95/47043.jpg" alt="犁过的田地" style="zoom:50%;"></p>
<p>&emsp; 柏树。采用大面积的对比色，重色块就是重色块，虽然笔触是翻飞的，色块是完整的规整的，是设计出来的。(树的色块绝对不对出现在天空中)<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/10/4978.jpg" alt="两株柏树"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/97/48060.jpg" alt="柏树下的两个女人"></div></div><div class="group-picture-row"></div></div></div></p>
<p>&emsp; <strong>特点：色块；笔触；符号化的夸张；秩序、逻辑感。</strong><br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/95/47046.jpg" alt="洛林夫人的画像"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47974.jpg" alt="看书的吉怒夫人"></div></div><div class="group-picture-row"></div></div></div></p>
<p>&emsp; 梵高的素描：从简单的黑白灰到逐渐符号化(这里就懒得放图了orz)。</p>
<p>&emsp; 向日葵：<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47991.jpg" alt="三朵向日葵"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47996.jpg" alt="十二朵向日葵"></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/96/47915.jpg" alt="十二朵向日葵"></div><div class="group-picture-column" style="width: 50%;"><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/95/47060.jpg" alt="十五朵向日葵"></div></div></div></div></p>
]]></content>
      <categories>
        <category>Art</category>
      </categories>
  </entry>
  <entry>
    <title>现代艺术与设计史2</title>
    <url>/2020/04/16/%E7%8E%B0%E4%BB%A3%E8%89%BA%E6%9C%AF%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8F%B22/</url>
    <content><![CDATA[<p>侧重艺术部分。<br>古希腊罗马，中世纪，文艺复兴，巴洛克，洛可可。<br>新古典主义：法国。达维特，安格尔。<br>浪漫主义：法国。德拉克洛瓦，透纳，戈雅，席里柯。<br>新古典主义建筑：(简要) 古希腊，古罗马，折衷主义，哥特。</p>
 <a id="more"></a>
<font color="#4F86C6">时间线：</font>

<p><img src="https://i.loli.net/2020/04/16/pEmriVTPAF2U5Ks.jpg" alt="IMG_20200416_220118.jpg"></p>
<p><strong>主观色系统:</strong> 圣母等等都有固定的颜色，例如 圣母蓝色袍(有时候黑袍子是因为蓝色很贵)金箔。<br><strong>固有色系统:</strong> 和模特穿的有关，不是固定的。不管当时的环境阳光，看到先入为主是红袍子就是红袍子。<br><strong>环境色系统:</strong> 不同时间段产生不同的颜色。教堂虽然是灰的，但是在不同时间受光部分可能是淡黄色的(固有色是灰的)。<br><strong>主观色系统:</strong> 不管是什么颜色，心中认为的颜色，饱含着每个艺术家对固有色和环境色的理解，是情绪化思想化的。</p>
<font color="#C5C6B6">关于中国：例如现代主义运动，虽然徐悲鸿等人也有参与，但是这门课不讲。</font>

<p>— <strong>古希腊和罗马：</strong>来源于古埃及的影响，奠定了西方文明的大部分准则，例如黄金分割，悲剧，古典英雄主义的题材，民主制度议会制度，对称平衡美学等等。<br>— <strong>中世纪：</strong> 漫长的一千年的祭奠。基督教从小众的教派逐渐成为国教(甚至到达巅峰时期时候教皇可以任免国王)。造型呆板。<br>— <strong>文艺复兴</strong>：题材变化不大，也是宗教题材，但是形式上开始追求世俗美。<br>— <strong>巴洛克</strong>：17世纪，中心是在意大利。卡拉瓦乔，贝尼尼，鲁本斯。<font color="#C5C6B6">巴洛克以前中心都是在意大利。</font><br>— <strong>洛可可：</strong>18世纪，中心是在法国。王权的艺术趣味成为主导，宫廷美学审美趣味从教皇到国王（路易十四十五，凡尔赛宫).  华托，布歇，弗拉戈纳尔。题材包括宫廷郊游，宫女，主要是宫廷生活男欢女爱等等.<br>— <strong>新古典主义：</strong>18-19世纪，中心是在法国。伴随着资产阶级革命的开始，权利法案等，资产阶级成为主角，开始反对洛可可繁琐奢华的宫廷趣味，希望能够返回到古希腊罗马时期的皇权创作。派生—学院主义。<br>— <strong>浪漫主义：</strong>18-19世纪，中心是在法国。几乎与新古典同期。</p>
<hr>
<h4 id="古希腊"><a href="#古希腊" class="headerlink" title="古希腊"></a><font color="#4F86C6">古希腊</font></h4><p>&emsp; 平衡匀称，静态美，虽然画的人物是动态的，但是追求的还是一种平衡。<br>&emsp; 并不强调本身肌肉/曲线的美感，追寻的还是对称 永恒 平衡 静态的美。<br><img src="https://i.loli.net/2020/04/23/iFPBMQvYhGCdHX8.png" alt="掷铁饼.png"><br><img src="https://i.loli.net/2020/04/23/1HvWx5zoIsrDY3m.png" alt="截屏2020-04-23下午1.20.16.png"></p>
<p>&emsp; 古罗马在形式艺术上完全照搬古希腊。但是在内容上会加上一些古罗马的神话题材(当时还是多神教)，另外还有给当时皇帝塑像(凯撒哈德良等等)。古罗马这一块这里暂时略掉了(十字军东征 西罗马解体等等自己去看)。</p>
<hr>
<h4 id="中世纪"><a href="#中世纪" class="headerlink" title="中世纪"></a><font color="#4F86C6">中世纪</font></h4><p>&emsp; 完全的基督教文明，造型呆板，人物半抽象化(这里指的是人物没有模特远行，画的都是圣母啊神之类的)<br><img src="https://i.loli.net/2020/04/23/wsbK6YfhxakMpoJ.png" alt="中世纪艺术.png"><br><img src="https://i.loli.net/2020/04/23/OBzQuajG2xwgEU8.png" alt="截屏2020-04-23下午1.26.38.png"></p>
<hr>
<h4 id="文艺复兴"><a href="#文艺复兴" class="headerlink" title="文艺复兴"></a><font color="#4F86C6">文艺复兴</font></h4><p>&emsp; 仍然是宗教题材的内容，但是人性化，世俗化，把世俗的人的审美表达出来。<br><img src="https://i.loli.net/2020/04/23/HSUsKgtNuQEn3MT.png" alt="截屏2020-04-23下午1.27.38.png"></p>
<h5 id="拉斐尔-意大利"><a href="#拉斐尔-意大利" class="headerlink" title="拉斐尔 (意大利)"></a>拉斐尔 (意大利)</h5><p>&emsp; 直接把自己的情人写生画出来变成圣母。拉斐尔那个时候已经是梵蒂冈的首席画师，相当于是那时候默许的。<br>&emsp; 造型是占主体的 <font color="#C5C6B6">变成黑白素描也能看</font></p>
<p>圣母子：<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/89/44047.jpg" alt="圣母子" style="zoom:67%;"></p>
<h5 id="达芬奇-意大利"><a href="#达芬奇-意大利" class="headerlink" title="达芬奇 (意大利)"></a>达芬奇 (意大利)</h5><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/70/34916.jpg" alt="蒙娜丽莎" style="zoom:57%;"></p>
<hr>
<h4 id="新古典主义"><a href="#新古典主义" class="headerlink" title="新古典主义"></a><font color="#4F86C6">新古典主义</font></h4><h5 id="达维特-法国"><a href="#达维特-法国" class="headerlink" title="达维特 (法国)"></a>达维特 (法国)</h5><p>达维特：Jacques-Louis David，1748—1825，法国。</p>
<p><strong>贺拉斯兄弟之誓</strong>，1784年，425x323cm<br>&emsp; 个人利益要服从国家利益；英雄主义，为国家献身的思想。<br>&emsp; 体现了古希腊的平衡美学，人物呈现三角的稳定关系；后面的拱门对称美学；平衡美学。<br><img src="https://i.loli.net/2020/04/16/mpiBd5rtgOG2Hb9.png" alt="截屏2020-04-16下午10.42.07.png" style="zoom:67%;"></p>
<p><strong>马拉之死</strong>，1793<br>&emsp; 虽然达维特年轻时候受到路易十六的资助，后来被派送到意大利学习，但是回国后导向革命党。马拉是雅各宾党人，受到了暗杀，如实记录了在浴室被暗杀的场景。(算是一种巧合的xie)<br>&emsp; 浴缸木箱子都起到平衡作用；人物位置黄金分割。均衡美学是典型的古典主义。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/79/39131.jpg" alt="马拉之死" style="zoom:67%;"></p>
<p>后来路易复辟，达维特作为雅各宾党派险些被处死。迎来政治生涯的低谷期。</p>
<p><strong>萨宾妇女</strong>，1799<br>&emsp; 古罗马时期。罗马人邀请萨宾人参加宴会，趁机悄悄偷袭了萨宾城，掠夺妇女和财产。双方战争关系。曾经被掠夺的萨宾妇女因为两边都是亲人，抱着幼儿跑去制止战争。<br>&emsp; 悲剧美学的矛盾性。相当平衡，妇女张开的双臂以及长矛，男性左右的平衡，站姿等腰三角形的脚。和现实主义差别巨大，现实主义是不加修饰的；这里有古典主义的古典美，经过修饰不是真实还原。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/76/37978.jpg" alt="萨宾妇女" style="zoom:67%;"></p>
<p>后来达维特导向了拿破仑，成为了拿破仑的首席画师。拿破仑有议会制度，资产阶级革命 英雄主义。于是题材逐渐变成了讴歌英雄主义的状态，是典型的古罗马希腊时候英雄主义的传统。</p>
<p><strong>拿破仑·波拿巴穿越大圣伯纳德山口</strong>，271x232cm<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/95/47132.jpg" alt="拿破仑" style="zoom:67%;"></p>
<p><strong>拿破仑一世加冕大典</strong>，1808-1822，610x931cm<br>&emsp; 长，庞大的作品。十分庄严肃穆。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Full/95/47133.jpg" alt="加冕"></p>
<h5 id="安格尔-法国"><a href="#安格尔-法国" class="headerlink" title="安格尔 (法国)"></a>安格尔 (法国)</h5><p>安格尔，Jean Auguste Dominique Ingres，1780-1867，法国<br>安格尔是达维特的学生，新古典主义也是学院派的画家。几乎从来不画表达英雄主义的古希腊罗马神话题材；但是画普通的女性，也是经过古典主义修饰过(类似于摆拍)，古典理想美。</p>
<p><strong>大浴女</strong>：<br>&emsp; 去掉了很多细小的结构，典型的美化修饰过的人体。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/76/37983.jpg" alt="大浴女" style="zoom:60%;"></p>
<p><strong>泉</strong>：<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/76/37961.jpg" alt="泉" style="zoom:60%;"></p>
<p><strong>大宫女</strong>：<br>&emsp; 很多时候作为解剖课的反例，都是画错的结构。是进行了美化、拉伸、柔美化的处理方法修饰过的。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Full/77/38146.jpg" alt="大宫女"></p>
<p><strong>布罗格利公主</strong>：<br>&emsp; 肖像画。中世纪时候没有肖像画，大多都是画圣母、耶稣之类的，文艺复兴时期开始有给教会富商画像(达芬奇)。到18 19世纪，已经有很多肖像的定制，类似于照相写实。<br>&emsp; 脸：更像是蜡像石膏，而不是完全真实的脸，修饰过的。但是其他地方，比如裙摆金箔，都非常的真实，所以是新古典主义。<br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/76/37953.jpg" alt="肖像" style="zoom:67%;"></p>
<hr>
<h4 id="浪漫主义"><a href="#浪漫主义" class="headerlink" title="浪漫主义"></a><font color="#4F86C6">浪漫主义</font></h4><h5 id="戈雅-西班牙"><a href="#戈雅-西班牙" class="headerlink" title="戈雅 (西班牙)"></a>戈雅 (西班牙)</h5><p>戈雅：Francisco José de Goya，1746 - 1828，西班牙<br>浪漫主义其实一点都不浪漫，有一点像现实主义。戈雅还画了很多与屠杀有关的作品，对后世产生了很大的影响(达利超现实主义等)。</p>
<p><strong>马德里枪杀</strong>，268x347cm<br>&emsp; 1808年5月3日马德里夜枪杀起义者。戈雅虽然没有亲眼看到这场枪杀(与现实主义不同)，但是是他这个时期发生的事情。<br><img src="https://blog.tshogx.top/2020/04/15/%E7%8E%B0%E4%BB%A3%E8%89%BA%E6%9C%AF%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8F%B2/%E7%8E%B0%E4%BB%A3%E8%89%BA%E6%9C%AF%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8F%B2/34416.jpg" alt="马德里枪杀"></p>
<h5 id="德拉克洛瓦-法国"><a href="#德拉克洛瓦-法国" class="headerlink" title="德拉克洛瓦 (法国)"></a>德拉克洛瓦 (法国)</h5><p>德拉克洛瓦：Eugene Delacroix，1798 - 1863，法国。浪漫主义代表人物。</p>
<p><strong>自由引导人民</strong>：<br>&emsp; 本身是在画法国革命，动荡暴力美学，与古典主义的修饰美学不同。例如画中的妇女粗壮的状态，不像以前一样处理地非常优美。<br><img src="https://i.loli.net/2020/04/17/C8iArzdWDpw6VbO.jpg" alt="自由引导人民.jpg"></p>
<p><strong>希阿岛的屠杀</strong>，345x419cm，1824<br>&emsp; 可以与古典主义达维特的《萨宾妇女》对比。描绘的是难民，真实的写照真实的美丑善恶；但是在当时引起了很多官方美学权威的反感，甚至将其称为”绘画的屠杀”。<br><img src="https://i.loli.net/2020/04/17/uVWRKzbD3Qi6d82.jpg" alt="希阿岛的屠杀.jpg" style="zoom:77%;"></p>
<p><strong>但丁的巴克</strong> (The Barque of Dante)<br>&emsp; 画的是但丁的神曲。图中的男性和女性甚至没有太多身体上的区分。与古典主义的修饰美学不同，浪漫主义更多的表现的是一种暴力的凄惨的；与库尔贝现实主义也不同，现实主义画的是亲眼所见的，但是对现实主义产生了重要的影响。<br><img src="https://i.loli.net/2020/04/17/qpl6fZ4MHAyETwv.jpg" alt="The_Barque_of_Dante.jpg"></p>
<h5 id="席里柯-法国"><a href="#席里柯-法国" class="headerlink" title="席里柯 (法国)"></a>席里柯 (法国)</h5><p>席里柯：Theodore Gericault，1791 - 1824，法国。席里柯还经常真正地到太平间去写生尸体。</p>
<p><strong>梅杜萨之筏</strong><br>&emsp; 海难，但是当时的官方掩盖了这个新闻。席里柯用绘画的形式报道出来了，悲剧。<br>&emsp; 在稳定中追求动荡，虽然远处的山脉是平稳的，但是近处不加修饰地表现出人物苍白的、发冷发黄的尸体。<br><img src="https://i.loli.net/2020/04/17/PkCyispMmqFaGjc.jpg" alt="梅杜萨之筏.jpg"></p>
<h5 id="透纳-英国"><a href="#透纳-英国" class="headerlink" title="透纳 (英国)"></a>透纳 (英国)</h5><p>透纳：Joseph Mallord William Turner, 1775-1851，英国</p>
<p>&emsp; 风景。对后来的印象主义表现主义抽象主义都有很大的影响。<br>&emsp; 把构成视觉的一些元素抽象出来，但是还不算纯粹的表现主义抽象主义，因为还是有叙事，画的是客观的现实物体。开始把光和色，瞬间产生的美感表现出来；但是色彩还没有那么丰富，依旧是固有色体系。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/Dz9gUp1qwu8QWiI.png" alt="Turner.png"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/9SVGRJ61h3acXFP.jpg" alt="透纳1.jpg"></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://i.loli.net/2020/04/17/dy2meKhO8C1pg3V.jpg" alt="透纳4.jpg"></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/AWSOVzZ1DEYcoPN.jpg" alt="透纳2.jpg"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/rWoLDzJm2MKxHsb.jpg" alt="透纳5.png"></div></div></div></div><br>&emsp; <font color="#D9D4CF">放大了看！！！Turner的画真的是太太太好看了！！！！！</font></p>
<hr>
<h4 id="新古典主义的建筑"><a href="#新古典主义的建筑" class="headerlink" title="新古典主义的建筑"></a>新古典主义的建筑</h4><p>1860-1960年期间的。和绘画一样，希望恢复古希腊罗马的风格，反对洛可可时期奢华的宫廷美学(凡尔赛宫)。伴随着资产阶级的发展而发展。<br>包括希腊复兴，罗马复兴，折衷主义，哥特复兴。</p>
<h5 id="希腊复兴"><a href="#希腊复兴" class="headerlink" title="希腊复兴"></a>希腊复兴</h5><p>&emsp; 古希腊，上面三角形，柱子支撑(平行)，有时候是两层柱子。上海外滩等很多都是模仿古希腊的。三种柱式。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/Snv5Vx6TcswiAE4.jpg" alt="GettyImages-rh256-552.jpg"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/8yR2OIVhJ4w16Ba.png" alt="柱式.png"></div></div><div class="group-picture-row"></div></div></div></p>
<h5 id="罗马复兴"><a href="#罗马复兴" class="headerlink" title="罗马复兴"></a>罗马复兴</h5><p>&emsp; 古罗马，保留了古希腊的柱子，但是作用更偏向于装饰性。柱子之间不是平行的，拱券，分散承重。穹顶是古罗马建筑的重要特点。<br><img src="https://i.loli.net/2020/04/17/DsUIXdRwKrCTtFo.jpg" alt="罗马建筑.jpeg"><br>&emsp; 拿破仑的凯旋门就是仿照的罗马建筑。<br>&emsp; 万神庙(Pantheon)，后面是一个巨大的穹顶，前面保留了古希腊的特点。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://i.loli.net/2020/04/17/XnExpZOVmUfeNsI.jpg" alt="万神庙.jpeg"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://i.loli.net/2020/04/17/3SHPe81NnFtrvhX.jpg" alt="万神庙俯瞰.jpg"></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://i.loli.net/2020/04/17/hQ7W1FNHMwejt4D.jpg" alt="万神庙2.jpg"></div></div><div class="group-picture-row"></div></div></div></p>
<h5 id="哥特复兴"><a href="#哥特复兴" class="headerlink" title="哥特复兴"></a>哥特复兴</h5><p>&emsp; 古罗马建筑只有最上面一个孔，很暗。为了增加内部光亮度，哥特建筑加了大量采光玻璃，为了追求天堂一般的明亮感。飞扶壁，受力，是为了大量开窗。建筑一般比较高(以前教堂是经常是城市最高的建筑，地标性)。整体看起来比较扎手。Eg：圣维特大教堂；米兰大教堂等。<br><img src="https://i.loli.net/2020/04/17/PMm2W5fKsUnNHAF.jpg" alt="圣维特大教堂.jpg" style="zoom: 67%;"><br><img src="https://i.loli.net/2020/04/17/Sb2iEX4fHNd5jlW.jpg" alt="飞扶壁.jpg" style="zoom:40%;"><br>&emsp; 英国国会大厦(哥特)，美国国会大厦(折衷主义)<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/SNCd3DQpUOG1lXe.gif" alt="英国国会.gif"></div><div class="group-picture-column" style="width: 50%;"><img src="https://i.loli.net/2020/04/17/6cuE21xDJBfNkH5.jpg" alt="美国2.jpg"></div></div><div class="group-picture-row"></div></div></div></p>
]]></content>
      <categories>
        <category>Art</category>
      </categories>
  </entry>
  <entry>
    <title>现代艺术与设计史1</title>
    <url>/2020/04/07/%E7%8E%B0%E4%BB%A3%E8%89%BA%E6%9C%AF%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8F%B21/</url>
    <content><![CDATA[<p>王受之先生主讲。主要讲述了课程的基本信息，梳理了艺术与设计的区别，大致的时间线框架，以及中国当今各个美院的前世今生。</p>
 <a id="more"></a>
<h4 id="Part-I"><a href="#Part-I" class="headerlink" title="Part I"></a>Part I</h4><font color="#548687" size="4">讲述艺术设计史的难度：</font>

<ol>
<li><p>艺术史时间跨度大 （纵向）</p>
<p>以中国为例。5000年，时间跨度太大内容多。</p>
<p>夏？暂时没有确切的考证。但是在商周时期已经有青铜、陶器，宫殿遗址，鄂、豫、陕等等地方都有成片的墓葬开掘。（其中河南安阳，甚至发现了大量的甲骨文，1921年）</p>
</li>
<li><p>全球 （横向）</p>
<p>全球范围内一共有五个中心；两河流域（美索不达米亚），埃及文明，地中海古希腊古罗马，印度河恒河文明，中国。其中两河流域和埃及文明可以追溯到公元前几千年。</p>
</li>
<li><p>重古轻今的现状</p>
<p>对现代艺术的了解和研究是在改革开放之后才逐渐发展起来的，研究现当代艺术的很少。过去的教学只教到德拉克罗瓦（浪漫主义），诸如1864年以后的印象派等等几乎没有不教。过去80年代曾有一大批前往西方学习的艺术家，但现在这方面有成就的艺术家比较少。</p>
</li>
<li><p><u>设计与艺术的区分:</u></p>
<p><font color="#529d9e"><strong>艺术</strong></font>: 只能单张创作，艺术家自我为中心，自我表现（抛开商业），没有确定的量化标准</p>
<p><font color="#529d9e"><strong>设计</strong></font>: 可以批量生产，功能性(用/看等)，服务型，以客户为核心</p>
<p>两者的定位截然不同，差异巨大，鉴赏标准完全不同。(因此课程中捏在一起讲难度比较大，来回switch)</p>
<p>在历史上两者是一起发展的。古代青铜：祭祀、武器、装饰品；陶器：用具、观赏品…….画画可能是为了装饰建筑器皿等等。直到文艺复兴中晚期，艺术绘画才从设计中脱离出来。（雕塑会更早一点，城市地标）</p>
</li>
<li><p>以设计为例，其包含的内容就太多了 （王院长真的是设计界大牛）。设计是有一定的量化标准的。</p>
<p>建筑设计（人与建筑是难以分开的，工具和遮蔽体；包括室内设计，景观设计，甚至到城市规划）；</p>
<p>产品设计（工业设计，包括军备汽车，衣食住行等消费产品设计，如食包括餐饮用具碗盏杯等等）；</p>
<p>服装设计（单独出来，衣服鞋等等，一种对个人的包装，时尚设计品牌）；</p>
<p>平面设计（例如字体直排有古典气息；视觉传达海报之类的强调功能性，要迅速传递信息；交互界面，手机等；影像设计，用影像来叙事等等）</p>
<p>其他等等等…</p>
</li>
</ol>
<hr>
<font color="#548687" size="4">审美：</font>

<ol>
<li><p>人对自然的审美<br>日出日落等（哪怕是不同的民族都喜欢）；瀑布（刺激类的）；</p>
<p><strong>物哀</strong>的能力，是人作为高等动物独有的，面对景物不仅产生审美带来的欣喜与快感，还会有景物产生的联想引起的忧伤等等。</p>
</li>
<li><p>对运动的欣赏</p>
<p>包括对人、其他动物等等。运动代表生命。Eg：奔马，奥林匹克，跳水，体操…</p>
</li>
<li><p>对艺术品的欣赏</p>
<p>视觉类的。欧洲早期很多画都是吹出来的。以前的人，运用夸张变形集中浓缩精简来作画，但是现代人过于讲究细节，很多时候表达不清未必画得好看。<u>学会用平面来记录一个三维形象</u>，画画，是一种很重要的能力。</p>
<p>石斧：将粗糙的石斧加工成圆润光滑的，两者在功能上没有什么不同，话费大力气只是为了追求审美和造型。玉做的石斧(最开始玉没有价值)，半透明，加工更难，但是好看。</p>
<p>对称美：因为人自身对称，两只眼睛。</p>
</li>
<li><p>语言文字美</p>
<p>中文：象形文字，用形来表示意；一音多义，字符多，难学。同时还使用声调(粤语九声，潮州十二声)。语法简单，在加上一音多字，造成了很多的不确定性。</p>
<p>文字本身好看，但是1956年实行第一次文字改革，大大简化，虽然改成了简体字写起来方便，但是不好看了。Eg：厂-廠(看不出含义了)；爱-愛(爱无心)；皇后-後(不同的字合并了)。</p>
<p>常用汉字只有4600个左右(会6000超级无敌厉害学者maybe)，但是康熙字典中收录了25万个。国外词汇量最丰富的俩，莎士比亚(超过20万个词)，丘吉尔(16万个)。日本大约有2000+个汉字(老汉字)，还有一些自身创造的。</p>
<p>关于文学形式：(音韵的重要性，平仄律，体现了一种审美)</p>
<p>最早的青铜器铭文，只需要500字就能写清楚一场战争的来龙去脉。</p>
<p>诗经。</p>
<p>骚体，屈原的离骚九歌等等，创造了神话一般的情境。</p>
<p>到秦朝大一统。再到后来汉代司马迁的史记，将文学与历史结合了起来(荷马)。</p>
<p>唐诗宋词；五言七言律诗。元代的元曲(关汉卿)戏剧等等；道白。明清的小说。</p>
<p>还有现代的电影等等，很多表现形式。</p>
</li>
</ol>
<hr>
<font color="#548687" size="4">推荐书籍：</font>

<p>房龙《艺术的故事》</p>
<p>贡布里希《艺术史》，范景中译(1981年，最早的一批)</p>
<p>《The history of Modern Art》, 邹德侬译(讲西方现代艺术，文艺复兴后19世纪中期～80年年代，每章后面会穿插讲建筑)</p>
<p>王受之教授自己出的书</p>
<p>李泽厚《美的历程》</p>
<hr>
<h4 id="Part-II"><a href="#Part-II" class="headerlink" title="Part II"></a>Part II</h4>]]></content>
      <categories>
        <category>Art</category>
      </categories>
  </entry>
  <entry>
    <title>6_003(I)</title>
    <url>/2020/02/15/6_003(I)/</url>
    <content><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p><strong>Abstraction</strong>: Describing a system; input, output<br><strong>Mathematics</strong>:<br>1.Solving differiential equations.</p>
<blockquote>
<p><strong>Ex1:</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
    y+3\dot{y}+2\ddot{y} &= 1\\
    2r^2+3r+1&=0 \text{(general solution)}, r = -1,-\frac{1}{2}\\
    y^{*}&=1\text{(specific solution)}\\
    \therefore y &=C_1e^{-t}+C_2e^{-\frac{1}{2}t}+1
\end{aligned}</script></blockquote>
<p>2.Geometric sum</p>
<blockquote>
<p><strong>Ex2:</strong> Use Taylor or division method.</p>
<script type="math/tex; mode=display">\frac{1}{(1-a)^2} = 1+2a+3a^2+4a^3+\cdots</script></blockquote>
<p>3.Partial fraction<br>4.Multiplying polynomials <em>(e.g. tabular representation)</em><br>5.Complex Numbers: $e^{j\theta} = \cos\theta+j\sin\theta$</p>
<p><strong>CT transformation</strong>: odd/even, shift, scaling…</p>
<hr>
<h3 id="DT-Systems"><a href="#DT-Systems" class="headerlink" title="DT Systems"></a>DT Systems</h3><p><strong>Unit sample:</strong></p>
<script type="math/tex; mode=display">
\delta[n]=
\begin{cases}1,&\text{if $n=0$}\\ 0, &\text{otherwise}\end{cases}</script><p><strong>Operator:</strong> $\mathcal{R}$, right-shift operator<br><strong>Fundamental modes:</strong> e.g. $y[n]=(0.5)^n$</p>
<p><strong>Multiple representations:</strong></p>
<ul>
<li>Verbal description</li>
<li>Difference equation: <font color="#999cc">precise and concise</font></li>
<li>Block diagram: <font color="#6699c">(start at rest)</font>  <font color="#999cc"> trace the flow of information</font><ul>
<li>step-by-step</li>
<li>operator approach, polynomials</li>
</ul>
</li>
</ul>
<font color="#99cccc">Lumping: from samples to signals<br>Declarative vs. Imperative (equation; diagram)<br>Recipe vs. Constraint<br>Acyclic vs. Cyclic<br>Finite vs. Infinite response</font>

<h4 id="Standard-form-DT"><a href="#Standard-form-DT" class="headerlink" title="Standard form (DT)"></a>Standard form (DT)</h4><p><strong>Geometric growth: pole</strong> (unit-sample response)<br><img src="https://i.loli.net/2020/02/15/jJmCE96ug4f52Hn.png" alt="1.png" style="zoom: 67%;"></p>
<script type="math/tex; mode=display">
y[n]=\begin{cases}p_0^n,& \text{if $n\geq0$;}\\0,&\text{otherwise.}\end{cases},H = \frac{Y}{X}=\frac{1}{1-p_0R}=1+p_0R+p_0^2R^2+\cdots</script><p>converge: |p|<1; &emsp; diverge: |p|>1</1;></p>
<p><strong>Second-Order System: poles</strong> (still unit-sample)<br>&emsp; see the Ex3.<br>&emsp; two methods: multipying polynomial; <u>partial fraction</u></p>
<p><strong>Complex poles:</strong><br>&emsp; Thinking about the difference equations, if the coefficients are real, even though the roots may be complex, the output is still <u>real</u>.<br>&emsp; <em>Note:</em> visualize the complex plane.</p>
<p><strong>Summary:</strong><br>Systems composed of adders, gains, and delays can be characterized by their poles.<br>The poles of a system determine its fundamental modes.<br>The unit-sample response of a system can be expressed as a weighted sum of fundamental modes.</p>
<h4 id="Z-tranform"><a href="#Z-tranform" class="headerlink" title="Z tranform"></a>Z tranform</h4><p>Replace $\mathcal{R}$ with $z^{-1}$.<br><strong>Def:</strong> (bilateral)</p>
<script type="math/tex; mode=display">X(z)= \sum\limits_{-\infty}^{\infty}x[n]z^{-n}</script><p><strong>Region of Convergence (ROC)</strong><br>&emsp; <font color="#666699"><i>Note:</i> For z transform, always consider both the functional form and the region of convergence.</font><br><strong>Properties:</strong><br>&emsp; 1.Linearity<br>&emsp; 2.Delay property &emsp; $x[n-1]\leftrightarrow z^{-1}X(z) $ for $z$ in ROC.<br><strong>IMPORTANT :</strong><br>&emsp; right-sided signal $\rightarrow$ outside region<br>&emsp; IF inside region, solve the difference equation by iterating backwards in time.<br><img src="https://i.loli.net/2020/02/16/DATSi4UWeRYP7zm.png" alt="截屏2020-02-16下午10.20.42.png" style="zoom:67%;"><br><strong>Inverse transform:</strong><br>&emsp; Formally, $x[n]=\frac{1}{2\pi j}\int_CX(z)^{n-1}dz $<br>&emsp; Better ways: partial fractions; using $\mathcal{R}$,….</p>
<hr>
<h3 id="CT-Systems"><a href="#CT-Systems" class="headerlink" title="CT Systems"></a>CT Systems</h3><p><strong>Unit impulse:</strong><br>&emsp; Unit area but zero width. (represented by an arrow with  the number 1)<br><strong>Unit step:</strong><br>&emsp; $u(t)=\int_{-\infty}^{t}\delta(t)dt = 1 \ (\text{only when }t\geq 0) $<br><strong>Operator:</strong> $\mathcal{A}$, accumulator,  $Y=\mathcal{A}X$ means $y(t)=\int_{-\infty}^{t}x(t)dt$</p>
<font color="#999cc">Fundamental operation: &emsp;Delays in DT are replaced by integrators in CT.</font> 

<h4 id="Standard-form-CT"><a href="#Standard-form-CT" class="headerlink" title="Standard form (CT)"></a>Standard form (CT)</h4><p><strong>Methods for solving CT Systems:</strong><br>&emsp; 1.differential equation $\rightarrow$ solve it;<br>&emsp; 2.use operators (Using poles; or Taylor series)<br><img src="https://i.loli.net/2020/02/16/m9GKhnLbPiql8VT.png" alt="2020-02-15.48.25.png"></p>
<script type="math/tex; mode=display">
\begin{aligned}
    \frac{Y}{X} &= \frac{\mathcal{A}}{1-p\mathcal{A}} = \mathcal{A}(1+p\mathcal{A}+p^2\mathcal{A}^2+p^3\mathcal{A}^3+\cdots)\\
    \text{if }x(t) &= \delta(t), y(t)= (1+\frac{1}{2}p^2t^2+\frac{1}{6}p^3t^3+\cdots)u(t)=e^{pt}u(t)
\end{aligned}</script><p>converge: p<0; diverge: p>0;</0;></p>
<h4 id="Laplace-tranform-CT"><a href="#Laplace-tranform-CT" class="headerlink" title="Laplace tranform (CT)"></a>Laplace tranform (CT)</h4><p><strong>Def:</strong> (bilateral)</p>
<script type="math/tex; mode=display">X(s)=\int_{-\infty}^{\infty}x(t)e^{-st}dt</script><p><strong>ROC:</strong> Thinking about convergence, only thinking about the real part.<br>&emsp; &emsp; &emsp; $e^{pt}=e^{(\sigma+jw)t}= e^{\sigma t}(\cos wt+j\sin wt) $<br>&emsp; &emsp; &emsp; right-sided signal $\rightarrow$ right-sided region</p>
<p><img src="https://i.loli.net/2020/02/16/uhV4pmaHMYnS3GC.png" alt="截屏2020-02-16下午11.19.45.png" style="zoom:67%;"></p>
<p><strong>Solving Differential equations with Laplace transform</strong>:<br>&emsp; Laplace transform of the derivative $\rightarrow$ s times the L-transform of the original function.</p>
<script type="math/tex; mode=display">
\mathcal{L}[\delta(t)]=X(s)=\int_{-\infty}^{\infty}\delta(t)e^{-st}dt=1</script><hr>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p><img src="https://i.loli.net/2020/02/16/STNeRHQ3BfvbPOX.png" alt="截屏2020-02-16下午6.05.59.png" style="zoom: 67%;"><br>Connections:</p>
<p><img src="https://i.loli.net/2020/02/16/QDuHfYV1mGS6EWr.png" alt="截屏2020-02-16下午10.48.55.png" style="zoom: 50%;"></p>
<hr>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><blockquote>
<p><strong>Ex3:</strong><br><img src="https://i.loli.net/2020/02/15/vzS49tU2lID8mkE.png" alt="2.png" style="zoom:67%;"></p>
<script type="math/tex; mode=display">
\begin{aligned}
&Y=X+1.6\mathcal{R}Y-0.63\mathcal{R^2}Y \\
&(1-0.7\mathcal{R})(1-0.9\mathcal{R})Y = X\\
&\frac{Y}{X} = \frac{1}{(1-0.7\mathcal{R})(1-0.9\mathcal{R})}
\end{aligned}</script><p>&emsp; <em>Note</em>: 可以将原来的diagram化成两个simpler system,cascaded system</p>
<font color="#ed5565">Method 1: </font> Multiplying polynomials
$$
\begin{aligned}
\frac{Y}{X} &=(1+0.7\mathcal{R}+0.7^2\mathcal{R^2}+\cdots)(1+0.9\mathcal{R}+0.9^2\mathcal{R^2}+\cdots)\\
&=1+(0.7+0.9)\mathcal{R}+(0.7^2+0.7\times0.9+0.9^2)\mathcal{R^2}+\dots\end{aligned}
$$
&emsp; <i>Note</i>: 可以用tabular

<font color="#ed5565"><br>Method 2: </font> Partial Fraction
$$
\begin{aligned}
    \frac{Y}{X}&=\frac{4.5}{1-0.9\mathcal{R}}-\frac{3.5}{1-0.7\mathcal{R}}\\
    \text{if } x[n] &= \delta[n],\ \text{then }\ y[n] = 4.5(0.9)^n-3.5(0.7)^n \text{ for $n\geq0.$}
\end{aligned}
$$
<font color="#ed5565">Check: </font>

</blockquote>
<p>&emsp;</p>
<blockquote>
<p><strong>Ex4:</strong> Find the poles of Fibonacci system.<br>&emsp; <font color="#ed5565">Key: </font> difference equation: $y[n] = y[n-1]+y[n-2]+x[n]$<br>&emsp; poles: 1.618… and  -0.618…</p>
</blockquote>
<font color="#9966CC">PS：可能不会再有了吧！<br>&emsp; &emsp; 这几百行打下来也太太太太费劲了吧！<br>&emsp; &emsp; 敲公式真的活生生敲出概率论作业的感jio啊！！！<br>&emsp; &emsp; 也只有在疫情爆发不能出门的日子里<br>&emsp; &emsp; 脑子抽了才会想整这个吧orz</font>



]]></content>
      <categories>
        <category>Courses</category>
      </categories>
  </entry>
  <entry>
    <title>2019-nCov</title>
    <url>/2020/02/03/2019-nCov/</url>
    <content><![CDATA[<p><center><font color="#5D478B">“秦人不暇自哀，而后人哀之，后人哀之而不鉴之，亦使后人而复哀后人也”。</font></center></p>
<p align="right"><font color="#5D478B">           ——杜牧《阿房宫赋》       </font></p>                  

<a id="more"></a>
<h3 id="官僚"><a href="#官僚" class="headerlink" title="官僚"></a>官僚</h3><blockquote>
<p>&emsp; 对个人的清算和追责是必要的，但倘若因此便忽视了社会与政治结构中所存在的顽疾，便是头痛医头、脚痛医脚的表面文章；甚至，这种针对个人的事后清算，只是弃卒保帅、化解公众不满的噱头罢了。</p>
<p>  &emsp;问题的关键并非个人或局部、而是在于整体，这一体制之中的每个部分、每个机关都并非无辜，而唯一找到解药的办法便是重新审视整个官僚体制的顽疾与弊病。</p>
<p>  &emsp;在这一政治结构中，主政官员的政治生命承受着来自上方的压力和监督，却无须像位于他下方的更接近基层的官员、以及这一结构终点处的被治理者负责，而后者亦尤其缺乏对前者的问责渠道。我们将这种情况称为官员<strong>问责性(Accountability)</strong>的缺失。</p>
</blockquote>
<p>​    在西方国家的体制中，基层的问责性通常通过市政选举(Municipal election)或公民团体(Civil society)来实现(包括但不限于支持竞争关系中的政党，参与公民团体等)。</p>
<p>​    关于结构性的思考，前段时间看到一片关于香港的文章中也有探讨。站在旁观者的角度，通过五大诉求真真正正拿到什么或许不是示威者最为关注的，其本身是希望通过这一持续性的具有影响力的运动，凸显体制下的结构性问题，以及香港人民在这一结构下的怨怼。当然其后演变出的种种、以及应当采取怎样的方式和手段就又是另一个话题了。</p>
<blockquote>
<p>&emsp;当然，西方国家的这种机制同样存在它独有的社会问题，例如选举中资源的浪费，”政党分肥“的腐败现象等，也需要较高的社会发展水平作为前提，因此并不一定适合于中国国情。</p>
</blockquote>
<p>​    然而，话说回来，当下这种体制的弊病确确实实是值得反思的，而当下关于其的讨论、认知由于种种因素都少得可怜，更遑论改进了。</p>
<blockquote>
<p>&emsp;然而，这种压力来源于政治结构，主政官员的理性抉择反而同时是不对民众负责、带来惨痛后果的决定，恰恰是证明我们所做的结构性批判重要且必要的最佳讽刺：<strong>稳定和绩效压倒知情权与风险防范在外面的体制下是正确而理性的</strong>，正如同资本家倾倒过度生产的牛奶在资本主义体制下也是正确而理性的选择那样，恰恰体现了这种体制内在逻辑的荒谬之处。</p>
</blockquote>
<h3 id="谣言"><a href="#谣言" class="headerlink" title="谣言"></a>谣言</h3><p>【谣言】与【辟谣】其实是很有意思的一组话题。</p>
<p>​    我们姑且先将 <u><em>谣言</em></u> 定义为 不真实的言论。</p>
<font color="666cc">PS: 期待了很久的尼尔森斯交响乐巡演被迫取消了qwq</font>

<h3 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h3><p><a href="https://matters.news/@philosophia/%E5%AF%B9%E6%9C%AC%E6%AC%A1%E7%96%AB%E6%83%85%E7%9A%84%E7%BB%93%E6%9E%84%E6%80%A7%E5%8F%8D%E6%80%9D-%E8%B0%A3%E8%A8%80-%E5%AE%98%E5%83%9A%E5%92%8C%E5%9B%BD%E5%AE%B6%E4%B8%BB%E4%B9%89-%E4%B8%8A-zdpuAzU8UUWBV3sB7c9h6FVbGZSrsc9L9qUEdHBBpDRJzTHzu" target="_blank" rel="noopener">对本次疫情的结构性反思：谣言、官僚和国家主义</a></p>
]]></content>
      <categories>
        <category>Book/Movie/Idea</category>
      </categories>
  </entry>
  <entry>
    <title>Performance of Multi-armed Bandit Algorithms</title>
    <url>/2020/01/14/Performance-of-Multi-armed-Bandit-Algorithms/</url>
    <content><![CDATA[<p><center><font size="6">Performance of Multi-armed Bandit Algorithms</font></center></p>
<h3 id="Basic-Setting"><a href="#Basic-Setting" class="headerlink" title="Basic Setting"></a>Basic Setting</h3><p>&emsp; The multi-armed bandit problem is a classic reinforcement learning problem which indicated the dilemma between the exploitation and exploration.<br>&emsp; We consider a time-slotted bandit system ($t = 0,1,2,\dots$) with three arms. We denote the arm set as $\{1,2,3\}$. Pulling each arm $j$ ($j\in\{1,2,3\}$) will obtain a reward $r_j$, which satisfies a Bernoulli distribution with mean $\theta_j$, </p>
<script type="math/tex; mode=display">
r_j = \begin{cases}1, &w.p. \ \theta_j\\0, &w.p.\ 1-\theta_j,\end{cases}</script><p>where $\theta_j$ are parameters within (0,1) for $j\in\{1,2,3\}$</p>
<p>&emsp; Now we run this bandit system for $N$ ($N$ ≫ 3) time slots. At each time slot $t$, we choose one and only one arm from these three arms, which we denote as $I(t)\in \{1,2,3\}$. Then we pull the arm $I(t)$ and obtain a reward $r_{I(t)}$. Our objective is to find an optimal policy to choose an arm $I(t)$ at each time slot $t$ such that the expectation of the aggregated reward is maximized, $i.e.$, </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t=1,\dots,N}^{}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right].</script><p> If we know the values of $\theta_j, j\in\{1,2,3\}$, this problem is trivial. Since $r_I(t)\sim$ Bern($\theta_{I(t)}$), </p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = \sum\limits_{t=1}^{N}\mathbb{E}\left[r_{I(t)}\right] = \sum\limits_{t=1}^{N}\theta_{I(t)}.</script><p>Let $I(t) = I^* = \text{argmax}\theta_j$ for $t=1,2,\dots, N$, then </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t = 1,\dots, N}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = N\cdot \theta_{I^*}.</script><p> &emsp; However, in reality, we do not know the values of $\theta_j, j\in\{1,2,3\}$. We need to estimate the values $\theta_j$ via empirical samples, and then make the decisions at each time slot. </p>
<h3 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h3><p>&emsp; Suppose we obtain the Bernoulli distribution parameters from an oracle, which are shown in the following table below. Choose $N$ = 10000 and compute the theoretically maximized expectation of aggregate rewards over $N$ time slots. We call it the oracle value. Note that these parameters $\theta_j, j\in\{1,2,3\}$ and oracle values are unknown to the three bandit algorithms. </p>
<p><img src="https://i.loli.net/2019/12/07/NTqe1RVjytgcUu8.png" alt="theta_table.png"></p>
<p>Therefore, we have that </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t = 1,\dots, N}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = N\cdot \theta_{I^*} = 1000\times 0.8 = 8000.</script><p>We design three algorithms as follows to maximize the aggregated reward.</p>
<h4 id="epsilon-Greedy-Algorithm"><a href="#epsilon-Greedy-Algorithm" class="headerlink" title="$\epsilon$ - Greedy Algorithm"></a>$\epsilon$ - Greedy Algorithm</h4><p><strong>Main idea:</strong></p>
<p>&emsp; An $\epsilon$ - greedy policy is that simply explores (choose one arm randomly) with probability $\epsilon$ , or otherwise greedily exploits the information we already have and thereby choose the arm with current hightest reward.<br>&emsp; Let $\hat{\theta}(j)$ be the average expectation reward for arm $j$   ($\ j\in\{1,2,3\}\ $). $I(t)\in\{1,2,3\}$ denotes the arm we choose;  $count$$(j)$ is the number of how many times arm $j$ has been chosen.<br>&emsp; Therefore, for each time slots (we have N in total), we decide the arm $I(t)$ by explorarion or exploitation. After that, $count$($I(t)$) increases by 1.  Suppose that arm $I(t)$ has been picked for $n$ times and results in reward $x_1,x_2,\dots,x_n$, $count(I(t)) = n+1$.</p>
<script type="math/tex; mode=display">
\begin{aligned}\hat{\theta}_n &= \frac{x_1+\dots+x_n}{n}\\ \hat{\theta}_{n+1} &= \frac{x_1+\dots+x_n+x_{n+1}}{n+1} = \frac{n\hat{\theta}_n+x_{n+1}}{n+1}= \hat{\theta}_n+\frac{1}{count(I(t))}(r_{I(t)}-\hat{\theta}_n) \end{aligned}</script><p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/meOgqKLtvWhbHrl.png" alt="Greedy_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results</strong><br>&emsp; We compute the expectation, and plot the actual reward and average reward against time slot ($t=1,2,\dots,N$). Due to the large scale of $N$, to see more clearly, we set the $x$ axis to be the $\lg N$.<br>&emsp; To see the exact performance of each earm, we also plot the the reward of each arm. If the arm is not chosen, we set the reward to be -1 as a default assignment. Each time when a arm is chosen, we alternate the default reward ($-1$) with the actual reward ( $0$ or $1$ ).<br>&emsp; To reduce the experiment error, we repeat the experiment for $100$ times and take the average values as outputs.<br>&emsp; Here are the code and results.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="comment"># #initialize</span></span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">    result = []</span><br><span class="line">    eposilong = eval(input(<span class="string">"epsilon:"</span>))</span><br><span class="line">    temp = [];temp2 = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        reward = [];avg = []</span><br><span class="line">        r = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; amr1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">            choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">                index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][t])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r[index][t]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                amr1[t] = r[index][t]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r[index][t]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward); temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(amr1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig1= plt.figure()</span><br><span class="line">    plt.title(<span class="string">"Epsilon-Greedy"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"mediumseagreen"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.sca(fig2)</span></span><br><span class="line">    fig2 = plt.figure()</span><br><span class="line">    plt.title(<span class="string">"Epsilon-Greedy"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>epsilon:0.1
mean= 7787.06
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/BtQdJDNVPlZOrwq.png">
    <img src="https://i.loli.net/2020/02/14/5uUVwkdMngYNAeC.png">
</figure>




<pre><code>epsilon:0.5
mean= 7002.36
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/qZObw6FspnDVYr8.png">
    <img src="https://i.loli.net/2020/02/14/okhVwWcCJvSDUXE.png">
</figure>




<pre><code>epsilon:0.9
mean= 6199.36
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/8TEhkbCxUeqDBrn.png">
    <img src="https://i.loli.net/2020/02/14/uPl5Zfb7FQBrN4Y.png">
</figure>



<p>According to the simulation, we observe that:</p>
<ul>
<li>$\epsilon$ denotes the probability of exploration. Therefore, when $\epsilon = 0.1$, the average reward almost converges to 0.8 (but still not reach 0.8, because we always has $\epsilon$ probability to explore), the actual reward almost oscillates near 0.8. We also see that as time goes by, we are more likely to choose arm 3 and only choose arm 1 or 2 in the exploration phase. </li>
<li>Compared to $\epsilon = 0.1$, when $\epsilon$ is higher, we get worse aggregated expectation. Because when it comes to large time slot, we already know that the third arm deliver the best performance. If $\epsilon$ is still high and if we are still exploring, it would drag down the aggregated reward. Additionally, if $\epsilon$ is too high, we only have small probability to exploit arm3 as shown in the figure.</li>
</ul>
<p>However, is it always the case that — when $\epsilon$ increases, we get worse performance? We set $\epsilon = 0.005, 0.01, 0.1,  0.3, 0.5, 0.75$, set $N=1500$ and do the simulation again.<br>Here are the code the result.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">1500</span></span><br><span class="line">e = [<span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.1</span>,<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.75</span>]</span><br><span class="line">c = [<span class="string">"#fe4365"</span>,<span class="string">"#3b8686"</span>,<span class="string">"#6a60a9"</span>,<span class="string">"#f9a11b"</span>,<span class="string">"#03a6ff"</span>]</span><br><span class="line">style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">    x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">    eposilong = e[o_]</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    r = []</span><br><span class="line">    HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">    count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    exp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">        choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">            index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">        count_j[index] += <span class="number">1</span></span><br><span class="line">        HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">        reward.append(r[index][t])</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">            exp += <span class="number">1</span></span><br><span class="line">        avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">    plt.plot(list(range(N)),avg,color =c[o_],label=e[o_],linewidth = <span class="number">1</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/02/14/I4SUqg1vZyu3oPR.png" alt="png"></p>
<p>$\ \ \ $We notice that if $\epsilon$ is too small, we do too little exploration, therefore, we may not get an accurate understanding of the arm performance. Therefore, the total reward is decreased.</p>
<h4 id="Improvement-of-epsilon-Greedy-Algorithm"><a href="#Improvement-of-epsilon-Greedy-Algorithm" class="headerlink" title="Improvement of $\epsilon$-Greedy Algorithm"></a>Improvement of $\epsilon$-Greedy Algorithm</h4><p>$\ \ \ $We design an improved $\epsilon$-Greedy algorithm to get better performance. The motivation is that — when $t$ is small, we set large $\epsilon$ to explore and obtain information quickly; when $t$ is large, we set small $\epsilon$ and exploit the information we already have. Shown as the follows, we set $\epsilon = t^{-\frac{1}{2}}$. We remain the $N=10000$ and repeat the experiments for 100 times just as previous experiments.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">10000</span></span><br><span class="line">theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">result = []</span><br><span class="line">eposilong = <span class="number">0.0</span></span><br><span class="line">temp = []</span><br><span class="line">temp2 = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    r = []</span><br><span class="line">    HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">    count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    exp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">        eposilong = <span class="number">1</span>/((t+<span class="number">1</span>)**(<span class="number">1</span>/<span class="number">2</span>))   <span class="comment">####This is the improvement.</span></span><br><span class="line">        choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">            index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">        count_j[index] += <span class="number">1</span></span><br><span class="line">        HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">        reward.append(r[index][t])</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">            exp += <span class="number">1</span></span><br><span class="line">        avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">    result.append(exp)</span><br><span class="line">    temp.append(reward) </span><br><span class="line">    temp2.append(avg)</span><br><span class="line"></span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">ax.hist(result, color = <span class="string">"#58c49f"</span>, bins=<span class="number">20</span>, edgecolor = <span class="string">"darkslategrey"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Expectation"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line">plt.title(<span class="string">"Improved Epsilon-Greedy"</span>)</span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">plt.xlabel(<span class="string">'log(N)'</span>)</span><br><span class="line">plt.plot(x,reward,color = <span class="string">"seagreen"</span>, label=<span class="string">"reward"</span>)</span><br><span class="line">plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>mean= 7956.26
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/AX9hIqKeQiEpxOC.png">
        <img src="https://i.loli.net/2020/02/14/bDOpRHTK2fYhxua.png">
</figure>



<p>As a result, we discovery that the new aggregated reward is much closer to 8000; the reward and average reward converge to 0.8 more quickly.</p>
<h4 id="Upper-Confidence-Bound-UCB-Algorithm"><a href="#Upper-Confidence-Bound-UCB-Algorithm" class="headerlink" title="Upper Confidence Bound (UCB) Algorithm"></a>Upper Confidence Bound (UCB) Algorithm</h4><p><strong>Main idea:</strong></p>
<p>$\ \ \ $First, we pull each arm once for initialization.</p>
<p>$\ \ \ $For $t = 4,\dots, N$, we choose the arm with highest Upper Confidence Bound (UCB).</p>
<script type="math/tex; mode=display">
I(t) \leftarrow \text{argmax}\left(\hat{\theta}(j)+c\cdot\sqrt{\frac{2\ln t}{count(j)}}\right)</script><p>where $\hat{\theta}(j)$ is the average reward observed from arm $j$ , $c$ is a constanst, $t$ is the number of attempts so far, $count(j)$ is the number of times arm $j$ has been pulled. In this formula, the first part is the exploitation term and the second part is the exploration term.</p>
<p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/xwMdfe7CrQpXG2V.png" alt="UCB_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    result = []</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>] </span><br><span class="line">    temp = [];temp2 = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    c = eval(input(<span class="string">"c:"</span>))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):   <span class="comment">###in total 100 repeats</span></span><br><span class="line">        <span class="comment">##initialize</span></span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        reward = []; avg = []</span><br><span class="line">        r = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; arm1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        count_j = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        argm = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = <span class="number">1</span>, p = theta_j[i])))</span><br><span class="line">            HTHETA_J[i] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==i:</span><br><span class="line">                arm0[<span class="number">0</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==i:</span><br><span class="line">                arm1[<span class="number">1</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[<span class="number">2</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">        reward = [r[<span class="number">0</span>][<span class="number">0</span>],r[<span class="number">1</span>][<span class="number">0</span>],r[<span class="number">2</span>][<span class="number">0</span>]]</span><br><span class="line">        r[<span class="number">0</span>] = r[<span class="number">0</span>]+[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        r[<span class="number">1</span>] = [<span class="number">0</span>] + r[<span class="number">1</span>] + [<span class="number">0</span>]</span><br><span class="line">        r[<span class="number">2</span>] = [<span class="number">0</span>,<span class="number">0</span>]+r[<span class="number">2</span>]</span><br><span class="line">        avg = [reward[<span class="number">0</span>]/<span class="number">1</span>,(reward[<span class="number">0</span>]+reward[<span class="number">1</span>])/<span class="number">2</span>,(reward[<span class="number">0</span>]+reward[<span class="number">1</span>]+reward[<span class="number">2</span>])/<span class="number">3</span>]</span><br><span class="line">          </span><br><span class="line">        <span class="comment">##UCB</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">3</span>,N):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                argm[j] = HTHETA_J[j] + c*math.sqrt(<span class="number">2</span>*math.log(t)/count_j[j])</span><br><span class="line">                r[j].append(int(bernoulli.rvs(size = <span class="number">1</span>,p = theta_j[j])))</span><br><span class="line">            index = argm.index(max(argm[<span class="number">0</span>],argm[<span class="number">1</span>],argm[<span class="number">2</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/(count_j[index])*(r[index][<span class="number">-1</span>]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r[index][<span class="number">-1</span>]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                arm1[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            avg.append(exp/t)</span><br><span class="line">    </span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward); temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(arm1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    fig1= plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"orange"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    fig2 = plt.subplots()</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>c:1
mean= 7892.49
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/1lwMLGtWxE7NX3C.png">
        <img src="https://i.loli.net/2020/02/14/HGfat1wgMFrUByE.png">
</figure>




<pre><code>c:5
mean= 7148.43
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/SOJrDXma9koQzB8.png">
        <img src="https://i.loli.net/2020/02/14/DV4BN3ISxnYCLXK.png">
</figure>




<pre><code>c:10
mean= 6676.07
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/Nh8JgZ1BsMnX7Lp.png">
        <img src="https://i.loli.net/2020/02/14/zjOSpNYCBl1a4T9.png">
</figure>




<p>According to the simulation:</p>
<ul>
<li>Each time the best arm is selected, $\hat{\theta}(j)$ would increase, however, $count(j)$ also increases and cause the second term to decrease. On the other hand, each time an action other than arm $j$ is selected, $t$ increases and the whole term increase, which cause the arm more likely to be choosen next time. </li>
<li>The first term indicates the exploitation phase, and the second term indicates the exploration phase. Very silimar to the $\epsilon$ - Greedy Algorithm, if we set $c$ to be larger, then we do more exploration even $t$ is relatively large, and it would be very difficlut for the figure to converge to 0.8.</li>
</ul>
<h4 id="Improvement-of-UCB-Algorithm"><a href="#Improvement-of-UCB-Algorithm" class="headerlink" title="Improvement of UCB Algorithm"></a>Improvement of UCB Algorithm</h4><p>$\ \ \ $We design an improved UCB algorithm to get better performance. The motivation is that — when $t$ is small, we set large $c$ to explore and obtain information quickly; when $t$ is large, we set small $c$ and exploit the information we already have. Shown as the follows, we set $c = \frac{1}{\log(t)}$. We remain the $N=10000$ and repeat the experiments for 100 times just as previous experiments.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">1</span>):</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    result = []</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>] </span><br><span class="line">    result = [] </span><br><span class="line">    temp = []</span><br><span class="line">    temp2 = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):   <span class="comment">###in total 100 repeats</span></span><br><span class="line">        <span class="comment">##initialize</span></span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        avg = []</span><br><span class="line">        r = []</span><br><span class="line">        count_j = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        argm = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = <span class="number">1</span>, p = theta_j[i])))</span><br><span class="line">            HTHETA_J[i] = r[i][<span class="number">0</span>]</span><br><span class="line">        reward = [r[<span class="number">0</span>][<span class="number">0</span>],r[<span class="number">1</span>][<span class="number">0</span>],r[<span class="number">2</span>][<span class="number">0</span>]]</span><br><span class="line">        avg = [reward[<span class="number">0</span>]/<span class="number">1</span>,reward[<span class="number">1</span>]/<span class="number">2</span>,reward[<span class="number">2</span>]/<span class="number">3</span>]</span><br><span class="line">          </span><br><span class="line">        <span class="comment">##UCB</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">4</span>,N+<span class="number">1</span>):</span><br><span class="line">            c = <span class="number">2</span>/(math.log(t))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                argm[j] = HTHETA_J[j] + c*math.sqrt(<span class="number">2</span>*math.log(t)/count_j[j])</span><br><span class="line">                r[j].append(int(bernoulli.rvs(size = <span class="number">1</span>,p = theta_j[j])))</span><br><span class="line">            index = argm.index(max(argm[<span class="number">0</span>],argm[<span class="number">1</span>],argm[<span class="number">2</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/(count_j[index])*(r[index][<span class="number">-1</span>]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r[index][<span class="number">-1</span>]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            avg.append(exp/t)</span><br><span class="line">    </span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward) </span><br><span class="line">        temp2.append(avg)</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.hist(result, color = <span class="string">"wheat"</span>, edgecolor = <span class="string">"orange"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Expectation"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    <span class="comment">#plot the reward and average reward</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig,ax = plt.subplots()</span><br><span class="line">    plt.xlabel(<span class="string">'log(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"lightsalmon"</span>, label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>mean= 7965.27
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/WRXwVL6qOPGf3aQ.png">
        <img src="https://i.loli.net/2020/02/14/qFzJGKCTLocDb5m.png">
</figure>


<p>&emsp; On average, we get better performance.<br>&emsp; However, we also notice that, for some cases, the total reward is relatively small, the UCB algorithm is quite unstable and do not have a excellent lower bound.</p>
<h4 id="Thompson-Sampling-Algorithm"><a href="#Thompson-Sampling-Algorithm" class="headerlink" title="Thompson Sampling Algorithm"></a>Thompson Sampling Algorithm</h4><p><strong>Main idea:</strong><br>&emsp; We notice that in the UCB algorithm, we actually do not use the information of probability distribution.<br>&emsp; The next algorithm, however, we take full advantage of the information that each arm generates a Bernoulli distributed reward.<br>&emsp; In Thompson Sampling algorithm, we define a prior probability distribution for each arm, $\hat{\theta}(j)\sim\text{Beta}(\alpha_j,\beta_j)$. In the experiment, for arm $j$, if we observe there are $k$ success out of $m$ attempts, then we update the probability, i.e., $\hat{\theta}(j)\sim\text{Beta}(\alpha_j+k, \beta_j+n-k)$.<br>&emsp; The proof is shown as follows.</p>
<script type="math/tex; mode=display">
\text{Def: $X$ is the number of success.}\\
\begin{align*}
    \Theta&\sim\text{Beta}(\alpha,\beta), X|\theta\sim\text{Bin}(n,\theta)\\
    f_{\Theta}(\theta|X=k)&=\frac{P(X=k|\theta)\cdot f(\theta)}{P(X=k)} \\
    &=\frac{\binom{n}{k}\theta^k(1-\theta)^{n-k}\frac{1}{\beta(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_{0}^{1}P(X=k|\theta)f(\theta) d\theta}\\
    &=C\cdot \theta^{\alpha+k-1}(1-\theta)^{n-k+\beta-1}\\
    &\sim\text{Beta}(\alpha+k,n-k+\beta)
\end{align*}</script><p>&emsp; In the simulation, we first pull each arm once as initialization. For $t = 4,\dots, N$, we always pull the arm with highest $\hat{\theta}$.</p>
<p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/F3XxnkmMN87UHD1.png" alt="TS_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> beta</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">10000</span></span><br><span class="line">theta = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]</span><br><span class="line"><span class="keyword">for</span> oo <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    <span class="comment">#initialize</span></span><br><span class="line">    result = [] </span><br><span class="line">    temp = []; temp2 = []</span><br><span class="line">    a = []; b = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha1 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta1 = "</span>)))</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha2 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta2 = "</span>)))</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha3 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta3 = "</span>)))</span><br><span class="line">    <span class="keyword">for</span> o <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        exp = <span class="number">0</span>; aa=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]; bb=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">            aa[i] = a[i]; bb[i] = b[i]</span><br><span class="line">        reward = []; avg = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; arm1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(N):  <span class="comment">##对每一个time slot</span></span><br><span class="line">            HTHETA_j = []</span><br><span class="line">            <span class="comment">#sample model</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                HTHETA_j.append(float(beta.rvs(aa[j],bb[j],size = <span class="number">1</span>)))</span><br><span class="line">            index = HTHETA_j.index(max(HTHETA_j[<span class="number">0</span>],HTHETA_j[<span class="number">1</span>],HTHETA_j[<span class="number">2</span>]))</span><br><span class="line">            r = int(bernoulli.rvs(size = <span class="number">1</span>,p = theta[index]))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            reward.append(r)</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                arm1[t] = r</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r</span><br><span class="line">            avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">            aa[index] = aa[index] + r;bb[index] = bb[index] + <span class="number">1</span>-r</span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward);temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(arm1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig1= plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"Thompson Sampling"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"#A593E0"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.sca(fig2)</span></span><br><span class="line">    fig2 = plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"Thompson Sampling"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>alpha1 = 1
beta1 = 1
alpha2 = 1
beta2 = 1
alpha3 = 1
beta3 = 1
mean= 7988.33
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/QIyl51ag29CEKBo.png">
        <img src="https://i.loli.net/2020/02/14/mdQtvNkICz26u48.png">
</figure>


<pre><code>alpha1 = 2
beta1 = 4
alpha2 = 3
beta2 = 6
alpha3 = 1
beta3 = 2
mean= 7988.64
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/IoeMH4fhEQlPqkg.png">
        <img src="https://i.loli.net/2020/02/14/hd1S93Xq84TUBON.png">
</figure>


<p>According to the simulation: </p>
<ul>
<li>Different from $\epsilon$ - Greedy and UCB algorithm, as $t\rightarrow \infty$, the probability of chosen arm 1 and arm 2 almost converge to 0.</li>
<li>We notice that the prior distribution only makes small difference to the final reward. However, if the prior probability is more closer to the true probability, it would take less time to find out which arm is the best.</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>The overall reults is shown as follows:<br><img src="https://i.loli.net/2019/12/30/Tmkb8DSfuAnMNxH.png" alt="a.png" style="zoom:80%;"></p>
<h3 id="Dependent-Cases"><a href="#Dependent-Cases" class="headerlink" title="Dependent Cases"></a>Dependent Cases</h3><p>&emsp; In the previous situation, we assume the reward distribution of three arms are independent. Here, we provide a method to analyze the dependent multi-armed bandit problems.</p>
<h4 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h4><p>&emsp; To generalize the problem, we assume that there is a machine with $N$ arms that are grouped into $K$ clusters. Every arm in a single cluster are dependent, but arms in different clusters are independent of each other. Each arm $i$ has a fixed but unknown probability $\theta(i)$ of generating a success reward (i.e. $r_i = 1$). Let $[i]$ denotes the whole arm cluster which contains the $i$th arm, and define $C_{[i]}$ be the set of all arms in that cluster including the $i$th arm.<br>&emsp; Define $s_i(t)$ be the number of times arm $j$ successfully generates a reward in $t$ time slot, $f_i(t)$ be the number of times that arm $i$ fails to generate a reward, $\varphi(h_{[i]})$ be the prior probability distribution and function $h_{[i]}$ abstract out the dependence of arms on each other in one cluster.<br>&emsp; Therefore, we have that </p>
<script type="math/tex; mode=display">
\begin{align*}s_i(t)|\theta(i)&\sim |\text{ Bin}(s_i(t)+f_i(t), \theta_i)\\ \theta_i&\sim \varphi(h_{[i]})\end{align*}</script><p>&emsp; In each timeslot, we solve the problem in two steps:</p>
<pre><code>1. Selection step: Apply a specific policy to choose the arm to pull.
2. Update step: Use the result of the arm pull to update the information.
</code></pre><p>&emsp; We should notice the difference between independent and the dependent cases. In a independent situation, once arm $j$ is pulled, only the information of arm $i$ is updated. However, in the dependent cases, once an arm $i$ is chosen, the state of all arms in $C_{[i]}$ is changed.</p>
<h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><p>&emsp; In each time slot, for each cluster $i$, we computer the reward estimate $\hat{\theta}(i)$ and the corresponding estimate variance $\hat{\sigma}(i)$ of  each cluster. After that, we use a specfic policy (such as UCB, Thompson Sampling, etc.) to select a cluster. Finally, we use the policy to choose the “best” arm in that cluster. In this method, a good estimate reward should be accurate and converge quickly (i.e., $\hat{\sigma}(j)\to 0$ quickly).<br>&emsp;We have two strategies shown as follows. </p>
<ul>
<li>Mean Strategy:<ul>
<li>For all arm $j$ in cluster $C_j$, according to the Binomial distribution, we set the cluster characteristics as follows:<script type="math/tex; mode=display">
\begin{align*}\hat{\theta}(j) &= \frac{s_j}{s_j+f_j}\\\hat{\sigma}(j) &= (s_j+f_j)\hat{\theta}(j)(1-\hat{\theta}(j))\end{align*}</script>Here, the $s_j, f_j$ are posterior values.</li>
<li>However, we notice that in the mean strategy, if there is one “bad” arm in a cluster, then the total estimate reward is dragged down. Therefore, it might be difficult to find the best rewarded arm if its siblings perform terribly. So, we design another algorithm shown as follows.</li>
</ul>
</li>
<li>Max Strategy:<ul>
<li>In this strategy, each cluster is represented by the arm that is currently best in it. That is:<script type="math/tex; mode=display">
\begin{align*}\hat{\theta}(j) &= max_{i\in C_j}\{\hat{\theta}(i)\}\\\hat{\sigma}(j) &= \text{corresponding }\hat{\sigma}(i)\end{align*}</script></li>
<li>Compared to the mean strategy, this method would be closer to maximum success probability of cluster $j$. Because $\hat{\theta}(j)$ is not dragged down by its families.</li>
<li>However, this method neglects all observations of other arms in that cluster and does not take full advantage of all current information. </li>
</ul>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li>Slivkins, A. (2019). Introduction to multi-armed bandits. <em>Foundations and Trends in Machine Learning</em>. <a href="https://doi.org/10.1561/2200000068" target="_blank" rel="noopener">https://doi.org/10.1561/2200000068</a></li>
<li>Pandey, Sandeep &amp; Chakrabarti, Deepayan &amp; Agarwal, Deepak. (2007). Multi-armed bandit problems with dependent arms.. 721-728. </li>
<li>Connor Lee, Hoang Le, R. M. (2016). Multi-armed Bandits. Retrieved from <a href="http://www.yisongyue.com/courses/cs159/" target="_blank" rel="noopener">http://www.yisongyue.com/courses/cs159/</a></li>
</ol>
]]></content>
      <categories>
        <category>Courses</category>
      </categories>
      <tags>
        <tag>Project</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Life Science</title>
    <url>/2020/01/13/Introduction%20to%20Life%20Science/</url>
    <content><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p><strong>Branches of Biology</strong></p>
<ul>
<li>Agriculture</li>
<li>Bioengineering, Bioinformatics, Biomathematics, Biophysics, Biotechnology…</li>
<li>Genetics, Biochemistry, Cell biology, Developmental biology, Neurobiology, Immunobiology, Molecular biology, Evolutionary biology, Cryobiology, Structure biology…</li>
<li>Medicine, Anatomy pathology, Physiology, Psychobiology, Toxicology, Pharmacology…</li>
<li>Microbiology, Mycology, Virology, Botany, Zoology…</li>
<li>Marine biology, Freshwater biology, Astrobiology…</li>
<li>Ecology, Conservation biology, Biogeography, Paleobiology…</li>
</ul>
<p><strong>Cell Theory</strong></p>
<ul>
<li>A eukaryotic cell contains membrane-enclosed organelles. </li>
<li>Eukaryotic 真核； Cytoplasm细胞质；Membrane膜<br><img src="https://i.loli.net/2020/01/07/cZVpeLBiQoTx6gh.png" alt="Eukaryotic cell structure.png" style="zoom: 80%;"></li>
</ul>
<p><strong>Information</strong></p>
<ul>
<li>Genomics基因组学；Proteomics蛋白质组学</li>
<li>Important research development that made genomic and proteomic possible:<ul>
<li>“High throughout” technology</li>
<li>Bioinformatics</li>
</ul>
</li>
</ul>
<p><strong>Energy and Matter</strong></p>
<ul>
<li>物质可以循环，能量流动具有单向性<br><img src="https://i.loli.net/2020/01/08/lPbfNL8XzFuKGpt.png" alt="energy flow.png" style="zoom:80%;"></li>
</ul>
<p><strong>Interactions</strong></p>
<ul>
<li>from a cell to a ecosystem</li>
<li>Negative feedback: a loop in which the response reduces the initial stimulus<br><img src="https://i.loli.net/2020/01/08/znVYL2rtqh7QFUl.png" alt="negative feedback.png" style="zoom:80%;"></li>
</ul>
<p><strong>Methods</strong></p>
<ul>
<li>IlyaIlyich Mechnokov 吞噬现象<ul>
<li>理论：动物体内可能存在一种细胞，它能吃掉并消化外来的病原体微生物</li>
<li>实验手段：显微镜</li>
<li>实验结果：观察到刺尖周围围满了移动过来的细胞。这些可移动的细胞以及它们围绕着橘子刺尖的现象</li>
<li>联想到 人体内从血管迁移到感染部位的白细胞</li>
<li>假设 —&gt;  白细胞可能到感染部位吞噬细菌</li>
</ul>
</li>
<li>Ralph Steinmann：DC cell (Dendritic cell)</li>
<li>以上两者的启示： Seeing is believing.</li>
<li>小保方晴子: STAP技术，仅通过物理压力和酸浴就将小鼠细胞转变为胚胎干细胞， 韩春雨基因修饰技术</li>
</ul>
<p><strong>Structure</strong></p>
<ul>
<li>DNA：Self-complementary nature of the double helix suggested that <u>each strand could serve as a template for the synthesis of its complement</u>. A与T配对，G与C配对</li>
<li>Protein：Electrostatic forces stabilize the 3D structure fold.</li>
<li>The side chains of the <u>amino acids</u> determine the shape, properties, and thus functions of <u>proteins</u>.</li>
<li>Folded proteins are marginally stable. The <u>hydrophobic effect</u> plays a huge role in the stability of the folded protein.</li>
</ul>
<p><strong>Cell Membrane</strong></p>
<ul>
<li>Membrane lipids form <strong>bilayers</strong> in water</li>
<li>Cell membrane act as <strong>selective</strong> barriers; <strong>fluidity</strong></li>
<li>endoplasmic reticulum内质网；transport vesicle运输小泡；lysosome溶酶体；Golgi apparatus高尔基体；plasma membrane质膜；mitochondrion线粒体；lipid脂质； phospholipid磷脂</li>
<li>Typical membrane <strong>lipids</strong>: 极性头部亲水，非极性尾部疏水<br><img src="https://i.loli.net/2020/01/08/KDFScXoa4iBdwj5.png" style="zoom:50%;"></li>
<li>Phospholipids bilayers spontaneously close in on themselves to form sealed compartments.</li>
<li>Lipid bilayer is a two dimensional fluid  脂双层具有流动性</li>
<li>Cholesterol stiffens the membrane 胆固醇</li>
<li>The lipid layer is asymmetrical 不对称</li>
</ul>
<h3 id="表观遗传"><a href="#表观遗传" class="headerlink" title="表观遗传"></a>表观遗传</h3><p>引入：</p>
<ul>
<li>细胞代际间依赖于DNA初级序列的信息传递：遗传</li>
<li>细胞代际间不依赖于DNA初级序列的信息传递： 表观遗传</li>
</ul>
<p>基因总是<strong>不同时</strong>表达 (bacteria, mammal, 为了更好地利用)。<br><strong>细菌</strong>基因表达调控机制因：</p>
<ul>
<li>避免氨基酸过量合成：负反馈</li>
<li>如何激活基因表达：诱导表达<ul>
<li>Removing the repressor</li>
<li>Recruiting the activator</li>
</ul>
</li>
</ul>
<p><strong>真核生物</strong>发育过程中基因表达主要特色：</p>
<ul>
<li>Inheritance $\rightarrow$ Cell fate maintenance</li>
<li>Selectivity $\rightarrow$ Cell fate commitment</li>
</ul>
<p><strong>转录</strong>：<br><img src="https://i.loli.net/2020/01/08/TEpSCJy4URnIAPg.png" alt="transcription histone.png" style="zoom:100%;"><br><u>Transcription regulators.</u></p>
<ul>
<li>转录因子和增强子：促进转录(transcription)起始</li>
<li>转录因子活性受外界信号调控：以皮质醇为例，没有皮质醇时，受体inactive。cortisol分子与receptor结合，activated，gene表达</li>
<li>基因表达的<strong>正反馈</strong>调控是细胞命运<strong>记忆</strong>(表观遗传)的机制之一。<br><u>Chromatin remodeling complex, Histone modifying enzyme.</u></li>
<li>chromatin染色质； nucleosome核小体</li>
<li>DNA分子通过核小体的包裹及折叠形成染色体结构，染色体结构是基因表达的天然障碍。</li>
<li>基因表达时，chromatin-remodeling complexes locally reposition the nucleosomes that wrap naked DNA.  染色质重塑</li>
<li>Histone modification occurs on specific amino acids in the N’ terminus of histones组蛋白修饰发生在组蛋白N’末端的特定氨基酸上<img src="https://i.loli.net/2020/01/08/WaXzNFhdfMmp5jr.png" alt="histone tail.png" style="zoom:80%;"></li>
<li>Histone tails undergo different types of chemical modifications</li>
<li>A subset of these modifications can promote trancription in cis by unwinding the tightly packed chromatin structure</li>
<li>Readers of histone post-translational modifications (PTM)</li>
<li>Combinatorial readout of PTMs</li>
<li>Functional consequences of reading modified histones<br>Reader和writer的协同作用使组蛋白修饰可在细胞代际间进行传递(如图)<br><img src="https://i.loli.net/2020/01/08/8ugUhYAwlmRoOKz.png" alt="Histone modification reader.png"></li>
</ul>
<p>DNA甲基化和去甲基化：</p>
<ul>
<li>DNA methylation DNA甲基化</li>
<li>Methylated CpG: repressed gene repression;   </li>
<li>Unmethylated CpG: active or repressed genen expression</li>
<li>Unmethylated CpG recuits histone modifying enzymes to prevent DNA methylation</li>
<li>Methylated CpG leads to transcription repression</li>
<li>Patterns of DNA modifications are inheritable — maintenance methyltransferase<br><img src="https://i.loli.net/2020/01/08/iX2ejVo7qg84ULR.png" alt="maintenance methyltransferase, inheritable.png"></li>
</ul>
<p>“Master” regulators change cell fate through transcriptional and epigenetic reprogramming (通过转录和重编程改变细胞命运) — induced pluripotent cells(iPS)诱导多能细胞。<br>RNA-mediated regulation：</p>
<ul>
<li>X chromosome inactivation(X染色体失活)，RNA介导的转录因子沉默</li>
<li>Transgenerational epigenetic inheritance of acquired traits<ul>
<li>Certain paternal traits that are acquired in response to ancestral exposures, such as toxicant contact, mental stresses and diet changes, can be inherited by the offspring, suggesting that epigenetic inheritance can occur through the sperm.</li>
</ul>
</li>
<li>Evidence of RNA as the carriers:<ul>
<li>Injection of total sperm RNA into normal zygotes transfers the behavioral and metabolic alterations observed in the father into the offspring. </li>
<li>Injection of nine miRNA altered in sperm of stressed father into zygotes produces offspring with similar phenotypes. </li>
<li>tsRNA profile changes following environmental stress, and injection of tsRNA-enriched RNA fragments into zygotes recapitulate the paternal phenotype in the offspring. </li>
</ul>
</li>
</ul>
<p>How does sperm gain information from the environment?</p>
<ul>
<li>Membrane-embraced small vesicles外泌体</li>
</ul>
<p><mark>小结：</mark><br>表观遗传的主要机制：</p>
<ul>
<li>基因表达的正反馈调控</li>
<li>染色体(组蛋白/DNA)修饰</li>
<li>RNA介导的表观遗传</li>
</ul>
<h3 id="基因和基因组"><a href="#基因和基因组" class="headerlink" title="基因和基因组"></a>基因和基因组</h3><p>基因的重要性：基因是细胞功能得以复制的分子基础</p>
<ul>
<li>细胞功能：结构支撑、保护、运动、信息传递和存储、物质运输、免疫、再生…<br>$\uparrow$</li>
<li>功能执行分子：蛋白质、RNA、脂类分子、多糖类分子…<br>$\uparrow$</li>
<li>细胞功能复制的基础：基因</li>
</ul>
<p>基因得以执行其功能的物质基础：</p>
<ul>
<li>伴性遗传：基因存在染色体上 (果蝇红眼)</li>
<li>基因由DNA构成：肺炎链球菌实验</li>
<li>DNA结构的发现：X-ray diffraction</li>
<li>碱基配对是基因复制的基础：<ul>
<li>碱基对在内部</li>
<li>adenine(腺嘌呤)和thymine(胸腺嘧啶)配对</li>
</ul>
</li>
</ul>
<p>基因如何执行其功能：</p>
<ul>
<li>碱基配对是基因产生其他生物分子的基础</li>
<li>中心法则</li>
<li>转录是一个受到精密调控的过程：<ul>
<li>基因转录由RNA聚合酶催化进行</li>
<li>RNA聚合酶活性的调控：基因表达调控的复杂性：<ul>
<li>基因的组成性表达和时空特异性表达(RNA聚合酶基因，肌肉基因，胚胎基因)(转录因子的时空特异性结合DNA调控序列是基因选择性表达的主要原因)</li>
<li>多个基因的协调性表达(并联，串联模式)</li>
<li>选择性剪接：同一基因产生多个不同转录本(外显子，内含子)(成熟mRNA被保留下来的基因部分被称为外显子)</li>
</ul>
</li>
<li>基因边界的界定：启动子和终止子(起调控作用的DNA序列)。增强子。</li>
</ul>
</li>
<li>信使RNA(mRNA)到蛋白质分子的产生：<ul>
<li>mRNA分子跨核膜运输</li>
<li>tRNA，翻译，起始密码子，终止密码子</li>
</ul>
</li>
</ul>
<p>疾病基因的克隆：</p>
<p>传统方法：</p>
<ul>
<li>Families with disease history</li>
<li>Genetic polymorphism</li>
<li>局限性：limited to genetic diseases, dependency on rare genetic materials, paucity of known genetic polymorphism, lengthy process to map disease related gene</li>
</ul>
<p>Human Genome Project:<br>全基因组测序技术基础：</p>
<ul>
<li>分子克隆。  Shortgun approach鸟枪法</li>
<li>PCR(Polymerase Chain Reaction)聚合酶链式反应：变性，退火，延伸</li>
<li>双脱氧链终止法<br><img src="https://i.loli.net/2020/01/08/GxJ2UgqHc9I3D6d.png" alt="shuangtuoyanglianzhongzhifa.png"></li>
</ul>
<p>基因组计划：</p>
<ul>
<li>Goal：the complete mapping and understanding of all the genes of human beings</li>
<li>Major Tasks: Determining the order(sequence) of all the bases in our genome’s DNA; Making maps that show the locations of genes for major sections of all our chromosomes</li>
<li>2003: Finished version of human genome sequence completed</li>
</ul>
<p>人类基因组的特征：</p>
<ul>
<li>人类基因组测序的覆盖程度：99% coverage of euchromatic genome(常染色体)</li>
<li>基因组大部分区域不编码蛋白质</li>
<li>许多非编码序列由各类转座子(transposon)构成，转座子的行为可能促进基因组的进化<ul>
<li>Transposon can facilitate recombination between different chromosomes by providing homologous regions for crossing over转座子可通过提供用于杂交的同源区域来促进不同染色体之间的重组</li>
<li>Transposon may carry along a gene or a group of genes to a new position in the genome转座子可能将一个或一组基因携带到基因组中的新位置</li>
</ul>
</li>
<li>基因组的三维结构和动态变化</li>
</ul>
<p>人类基因组和疾病基因的发现：</p>
<ul>
<li>基因的位置标签：单核苷酸多态性</li>
<li>全基因组关联分析 Genome-wide Association Studies</li>
</ul>
<h3 id="基因遗传"><a href="#基因遗传" class="headerlink" title="基因遗传"></a>基因遗传</h3><p>有性繁殖的两大特征：遗传和变异</p>
<p>Gregor Mendel孟德尔：</p>
<ul>
<li>豌豆实验(显性隐性)</li>
<li>成功的关键因素：<ul>
<li>以七大“True-breeding”性状作为主要的检测指标</li>
<li>人工授精</li>
</ul>
</li>
<li>Law of segregation 分离定律</li>
<li>Law of independent assortment 自由组合定律</li>
<li>如果选择非”True-Breeding”性状：<ul>
<li>非完全显性性状</li>
<li>多个性状间相互作用</li>
<li>由多个基因决定的性状</li>
</ul>
</li>
</ul>
<h3 id="发育和干细胞"><a href="#发育和干细胞" class="headerlink" title="发育和干细胞"></a>发育和干细胞</h3><ul>
<li>Feritilization forms a diploid zygote and initiates embryonic development. 受精形成二倍体合子并开始胚胎发育</li>
<li>Early embryonic development consists of four key steps: cleavage (细胞分裂), blastulation (空腔形成), gastrulation (细胞分层), and neurulation (个体萌芽发育).</li>
<li>Cells undergo dramatic changes in cell shape and position during development, and cell death is essential for proper morphogenesis.</li>
<li>Cytoplasmic determinants(内因) and inductive signals(外因) contribute to cell fate specification. </li>
</ul>
<p>成体干细胞：<br>成体组织内存在干细胞。<br>单个造血干细胞可重建造血系统。<br>Raymond Schofield细胞龛理论(干细胞调控的外在机制)：</p>
<ul>
<li>细胞龛决定干细胞的维持<br>干细胞可以受其子代分化细胞的调控(小肠干细胞，造血干细胞)。<br>干细胞通过逐级分化产生成熟细胞(生长因子和转录因子介导的定向分化)。分化和去分化。</li>
</ul>
<p>干细胞多能性的诱导：</p>
<ul>
<li>体细胞核移植，体细胞干细胞融合</li>
<li>以猴子为例</li>
</ul>
<p>体细胞重编程：</p>
<ul>
<li>induced Pluripotent Stem (iPS) cells 诱导多能干细胞</li>
<li>Isolate and culture donor cells </li>
<li>Transduce stem cell-associated genes into the cells by viral vectors 通过病毒载体将干细胞相关基因导入细胞</li>
<li>Harvest and culture the cells according to ES cell culture (ES:胚胎干细胞)</li>
<li>A small subset of the transfected cells become iPS cells and generate ES-like colonies. </li>
</ul>
]]></content>
      <categories>
        <category>Courses</category>
      </categories>
      <tags>
        <tag>Biology</tag>
      </tags>
  </entry>
  <entry>
    <title>Bio Lecture</title>
    <url>/2020/01/07/Bio-Lecture/</url>
    <content><![CDATA[<h3 id="现代医学掠影"><a href="#现代医学掠影" class="headerlink" title="现代医学掠影"></a>现代医学掠影</h3><ul>
<li>现代医学的特点：是实验科学；有技术支撑（仪器设备、基因编辑、stem cell）；</li>
<li><p>现代医学史：</p>
<ul>
<li>原始医学：植物$\rightarrow$催吐止痛杀虫；部落战争$\rightarrow$创伤外科；</li>
<li>古代东方医学：埃及(药，简单手术)；印度(内外科，瑜伽运动)；古巴比伦(占星术)；中国(中医)；<br>古代西方医学：希腊希波克拉底(Hippocratic oath; father of the medicine)；罗马盖伦；<br><img src="https://i.loli.net/2020/01/06/BtQDRVKiAUyPFLJ.png" alt="Hippocratic oath.png" style="zoom: 50%;"></li>
<li>中世纪医学(Dark Age)：盖伦后到文艺复兴，科学和医学都没发展；</li>
<li><p>近代医学(文艺复兴-19世纪)：</p>
<ul>
<li>文艺复兴：<strong>Human Anatomy</strong> established, which overthrow Galenism doctrines based on Monkey Anatomy （达芬奇解剖图）</li>
<li><p>17世纪: <strong>Blood Circulation</strong>, Microscope<br>哈维：活体实验；体循环(心室)；</p>
<blockquote>
<p>发现血液循环，生理学确认为科学，引入实验，生物学成为<strong>实验科学</strong></p>
</blockquote>
</li>
<li>18世纪：免疫学建立（牛痘预防天花）</li>
<li>19世纪：Dramatic progress in 4 areas:<ul>
<li>细胞学、细胞病理学  (Schwann, Virchow)<br><img src="https://i.loli.net/2020/01/06/Vzi9ft5KaYuopFT.png" alt="细胞学细胞病理学.png" style="zoom: 80%;"></li>
<li>细菌学、免疫学  (Pasteur, Koch)<br>Pasteur: “Germ theory of disease”; wine/milk souring<br>​                “Father of <strong>Immunology</strong>“: attenuated/dead pathogen<blockquote>
<p>Vaccines made: Cholera霍乱； Anthrax； Rabies狂犬病<br>Koch: “Father of <strong>Microbiology</strong>“: tuberculosis肺结核<br>​            Koch Postulates柯霍法则：identify pathogens<br>​            techniques: bacteria photography, staining, isolating</p>
</blockquote>
</li>
<li>外科学：麻醉($\rm{N_2O}$)、消毒 (Lister: phenol苯酚)；      </li>
<li>诊断学：<u>听诊器</u>，血压计，体温计，体腔镜；    </li>
</ul>
</li>
</ul>
</li>
<li>现代医学：<ul>
<li>New drugs:<ul>
<li>梅毒Chemotherapy</li>
<li>青、链霉素Antibiotics</li>
<li>Therapeutic proteins produced by genetic engineering</li>
</ul>
</li>
<li>Organ transplants (cornea角膜，kidney肾, liver, lung, heart)</li>
<li>成像(X-ray, CT, ECT, MRI, PET)</li>
<li>基因诊断</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>饱和脂肪： 胆固醇$\rightarrow$心脏病</li>
<li>糖：胰岛$\rightarrow$糖尿病</li>
<li>不饱和脂肪酸、维生素、纤维素：有益</li>
</ul>
<ul>
<li>疾病的三个阶段： 潜伏期，前驱期，临床期（症状），转归期</li>
<li>死亡：传统死亡（心跳），脑死亡（脑干反射消失，无自主呼吸；提供新鲜器官，不是植物人）</li>
</ul>
<ul>
<li>缺维他命C：败血症（航海）</li>
<li>缺维他命B：脚气病（日本贵族）</li>
<li><p>矿物质的代表：食盐；为食草动物必需(血液和细胞间液的阳离子主要成分)；增添风味保存食物，发财致富</p>
</li>
<li><p>糙皮病的食物原因:玉米等高淀粉作物作为单一的主食 （将玉米粒用石灰水或 草木灰浸泡煮沸处理，增加烟酸的量，补充钙，以及减少霉菌毒素的摄入 </p>
</li>
<li>炭疽杆菌的武器现代化。可怕的性能：孢子化，高致病率和死亡率</li>
<li>细菌学的鼻祖Koch：分离鉴定了炭疽杆菌，结核杆菌，霍乱弧菌</li>
<li>青霉素Fleming，抗生素（问题：药物外排，种间抗药基因的水平传递）</li>
<li>传染病并不一定是细菌/病毒导致。疟原虫（疟疾，蚊虫叮咬是主要传播媒介），寄生虫</li>
<li>抗疟疾药：奎宁（金鸡纳霜，抑制血红素的降解），青蒿素</li>
<li>阿拉伯是实证科学的萌芽</li>
<li>构成生命的基本遗传单元：基因</li>
<li>基因：a distinct sequence of nucleotides forming part of a chromosome, the order of which determines the order of monomers in a polypeptide or nucleic acid molecule which a cell (or virus) may synthesize. </li>
<li>LEP gene mutation $\rightarrow$ obese</li>
<li>模式生物：饲养便宜，规避伦理问题，活体研究，生命周期短，我们需要<strong>减数分裂和精卵融合过程</strong></li>
<li>经典模式动物：黑腹果蝇（易于大量培养，生命周期10天，交配简单后代多）</li>
<li><p>过程：</p>
<ul>
<li>诱变产生突变体 $\rightarrow$ 筛选 $\rightarrow$ 定位基因 $\rightarrow$ 克隆基因</li>
<li>基因诱变：显性 / 隐性（绝大多数）</li>
<li>放射性诱变：染色体突变；  化学诱变剂(EMS)：突变缺失插入； 生物诱变剂：大片段插入突变</li>
<li>筛选（遗传图）</li>
<li>遗传定位(genetic mapping): 定位关键突变(causive mutation)在染色体上的位置</li>
<li>经典遗传定位：标记基因(marker)连锁交换率</li>
</ul>
</li>
<li><p>线虫：通体透明，容易大量培养，生命力强大；</p>
</li>
<li>线虫：雌雄同体</li>
<li>线虫突变体更长寿，这些突变也使得其他动物(包括哺乳动物变得长寿) Cynthia Kenyon</li>
<li>细菌调控荚膜多糖酸的基因突变会导致长寿；荚膜多糖酸的直接摄入也能导致寿命延长</li>
</ul>
<ul>
<li>生物技术：<ul>
<li>基因技术：测序，PCR，遗传工程(基因重组、分子克隆)，转基因，基因编辑</li>
</ul>
</li>
<li>消化系统 = 消化管 + 消化腺(唾液腺、胰腺、肝)</li>
<li>胰岛素测序</li>
<li>基因工程：质粒，载体，限制性核酸内切酶，DNA连接酶，转化，重组蛋白</li>
<li>Boyer创建Genetech，第一个生物技术公司，胰岛素生长素凝血因子等多个医用蛋白</li>
<li>修改生物(转基因、基因打靶)， 转基因小鼠(受精卵显微注射)； 经典打靶的局限性：只能打靶小鼠胚胎干细胞，time consuming，用途有限(小鼠)</li>
<li>基因编辑： CRISPR/CAS9是细菌的抗病毒武器<ul>
<li>普遍性：Cas9可以切任何序列(只要和crRNA互补)，内切酶只能切部分会问序列</li>
<li>专一性：crRNA识别20个碱基，基因组里只有一个靶点</li>
</ul>
</li>
<li>用途：疾病诊断治疗(医用蛋白,CRIDPR修改基因)，法医，农业转基因作物，控制有害物种</li>
<li>日本Nobel：严谨认真坚持</li>
</ul>
<h3 id="跨代表观遗传学"><a href="#跨代表观遗传学" class="headerlink" title="跨代表观遗传学"></a>跨代表观遗传学</h3><ul>
<li>有些环境刺激虽不诱发基因突变，却可以持久地改变基因功能，有些甚至可以遗传给后代</li>
<li>表观遗传学的两大焦点：染色质，<strong><u>非基因遗传</u></strong></li>
<li>非基因遗传 = epigenetic inheritance  = 表观遗传</li>
<li>细胞分裂时，基因的功能状态从母细胞传递给子细胞，这种信息传递就称为表观遗传。</li>
<li>有丝分裂是传统意义的表观遗传。</li>
<li>表观遗传的实质是基因记忆，短暂的环境刺激能持久地改变基因活性。</li>
<li>基因记忆的典型：X染色体随机失活；   DNA甲基化</li>
<li>配子必须去分化，才能变成全能细胞，胎儿才能发育。少数亲代表观遗传信息不能被重编程、抹去，成为漏网之鱼。</li>
<li>印记基因：来自某亲本的等位基因发生甲基化而沉默，导致一对基因中只表达一个(能够逃过重编程)</li>
<li>自私基因：表观沉默(将其埋在致密的染色质里)，甲基化锁定捆绑自私基因(有些不可逆)</li>
<li>宿主对付genome寄生虫：突变使其残废，表观沉默</li>
<li>两类跨代遗传：<ul>
<li>自然发生: imprinted gene, selfish gene</li>
<li>环境诱发<br><img src="https://i.loli.net/2020/01/07/uvoJQlOGLXKkD86.png" alt="非基因遗传.png"></li>
</ul>
</li>
<li>获得性遗传</li>
<li>后天获得的性状也可以遗传，但是比较少(线虫，小鼠都有例子)</li>
<li>加热使秀丽线虫变红，7-14代后才完全褪色</li>
<li>小鼠Cherry嗅觉基因 甲基化异常，嗅觉神经元增多</li>
<li><p>Decipher the mechanisms of transgenerational inheritance </p>
<ul>
<li>Cis：environmentally induced chromatin modifications can sometimes persist across generations, which may require special hypothetical insulator sequence that acts to preserve the modifications环境诱导的染色质修饰有时可能会持续几代，这可能需要特殊的假设绝缘子序列来保持修饰</li>
<li><p>Trans：线虫吃下有害菌，多死，侥幸活下的线虫，学会躲避，这个本领能传4代。小RNA(piRNA)传递这个形状</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">环境（例如饥饿和高温）调节着体细胞中的小RNA，可以进入种系并产生持续多个世代的反应</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/01/07/o1GCgNI7EfKzc3y.png" alt="Heritable environmental effects.png"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Nobel"><a href="#Nobel" class="headerlink" title="Nobel"></a>Nobel</h3><ul>
<li>Forward genetics (phenotype $\rightarrow $ causative gene):the approach to identify genes whose mutations cause a known phenotype <ul>
<li>自发</li>
<li>induced</li>
<li>常用在低等生物研究中，现在less popular</li>
</ul>
</li>
<li>Reverse genetics：已知序列，未知功能<ul>
<li>The approach to uncover the function of a known gene by manipulating the gene </li>
<li>KO method</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Courses</category>
      </categories>
      <tags>
        <tag>Biology</tag>
      </tags>
  </entry>
  <entry>
    <title>《斯通纳》</title>
    <url>/2019/10/15/%E3%80%8A%E6%96%AF%E9%80%9A%E7%BA%B3%E3%80%8B/</url>
    <content><![CDATA[<p>  除了作者的文字功力和叙述基调，这本书令我印象很深的一点在于坦诚。与其说是一本小说，其给人的感受反而更像是一本真实的人物传记。</p>
<p>  斯通纳不是卡尔维诺笔下树上的男爵，或者毛姆笔下偏执地逃离去荒岛的思特里克兰德。他是真实的，几乎不加艺术渲染的。他像绝大多数人一样，过着最最普通的生活——农民出身、进校学习、成为教师、结婚生子、因病逝世。</p>
<p> “这是一本关于失败者的书”。面对平庸的生活，作者所揭示的，就是“凡人中的勇者如何在生活”。</p>
 <a id="more"></a>
<h3 id="一"><a href="#一" class="headerlink" title="一."></a>一.</h3><p> 在斯通纳入学的若干年后，战争爆发。随着事态持续发酵，校园里布满血红的反德标语和高扬的美国国旗。因为愤怒和激动涨红脸的学生，围堵在教学楼前高声地呼喊抗议。</p>
<p> 无数像戈登一样的人自发走上了战场。他前所未有地迫切地感到自己是被需要的，他就像那些充满爱国主义情怀的多数人一样，怀揣着力量并希望将世界的一切纳入其中。这是他的信仰。</p>
<p> 更多的人像马斯特思一样奔赴战场，一去不复返。屠杀、鲜血、滚滚而来的死者的名录。爱与恨的二元对立像瘟疫般横扫大地。人们夸耀情怀、崇拜英雄，却忽视冰冰凉凉数字背后一个个鲜活的有血有肉的个体。记得很早以前在网上看到这样一句话：“History is more than some cold statistics in books. It is also about lives of individuals in times of turmoil and disaster.” </p>
<p> 历史的一小步，往往是数以千计人漫长的一生。</p>
<p> 有血有肉的人不应成为印制的模版或工具。</p>
<p> 所以斯通纳选择了留下。他拒绝参军，也因此受到别人的唾弃。我想我是理解他的。与外部世界相比，大学的学术圈子是与世隔绝的象牙塔；这是他的迦南之野，也是大庇天下寒士俱欢颜的小茅屋。他不是贪生怕死，也谈不上特别的热情或是对敌人特别的憎恨，他看似冷漠不近人情，却有着学者内心深处最温柔的同情和怜悯。战争，所屠戮掉的不仅仅是千千万万的年轻生命，甚至是一个民族心中的东西。文中的斯隆说：“如果一个民族经历了太多的战争，很快，剩下的就全都是残暴者了，动物，那些我们——你和我以及其他像我们这样的人——在这种污秽中培养出的动物。”</p>
<p> 威尔·杜兰特曾写道，文明就像是一条河流；河流中的鲜血是人们斗争厮杀的结果，这通常就是历史学家们所记录的内容；而他们没有注意到的是，在河岸上，人们建立家园、相亲相爱、养育子女、歌唱、谱写诗歌，甚至创作雕塑。</p>
<p> 人们不能请求学者去摧毁他拼尽全力所建构出来的东西。斯通纳选择了留下，去保护他所固执地追寻的美，从某种意义上说，这是学者的使命与责任。</p>
<h3 id="二"><a href="#二" class="headerlink" title="二."></a>二.</h3><p>​    斯通纳是失败的。他过着平庸无趣的生活，可他偏偏是个梦想家，“一个更疯狂世界的疯子，中西部本土的堂吉诃德，但没有自己的桑乔，在蓝天下欢跳”。平庸和理想的冲突成就了他的悲剧，他太固执。他总是觉得世界上有某种东西值得去寻找，但是他失败了。</p>
<p>​    棉花里的象虫，豆荚里的蠕虫，玉米里的穿孔虫，蛀虫无处不在而声势浩大。他太弱了，他不会也无法同这个世界拼搏。他悲哀地纠结着。</p>
<p>​    他做过许多斗争——</p>
<p>​    妻子伊迪丝，固执地希望将女儿格蕾斯培养成高贵却冷漠麻木的女子。为了防止斯通纳给女儿带来任何“不良”的影响，她近乎神经质地切断父女间的一切接触。“人的道德质地是柔软娇弱的，需要细心呵护才能称心如意。” 在这场教育分歧的斗争中，斯通纳失败了，他用尽全力却保护不了外部世界对格雷斯的伤害。他太渺小了。</p>
<p>​    在工作的斗争中，斯通纳又是失败的。沃尔克是个不学无术又喜欢自我吹嘘的关系户。为了维护自己所从事事业的圣洁，斯通纳执着地想要阻挠他的成功道路，可最终毫无结果，而且他还受到了报复。</p>
<p>​    随着第二次世界大战的爆发，历史的洪流和生活的摧残凶猛地冲击着他。斯通纳几乎用尽全身的气力忍受着。他几乎成为一个精神分裂的人——一方面在毁灭和死亡所带来的泛滥性冲击中恐惧着畏缩着；另一面又近乎自暴自弃地渴望介入毁灭的进程，品尝毁灭的苦涩快感。他是矛盾的——他的经历昭示着他的渺小和失败，他的力量远不足与击退反对他的残暴势力；而他的固执又不允许他放弃，他总是幻想着憧憬着却又失败着。这就是梦想家的悲哀。</p>
<p>​    “他既感到可耻，又感觉自豪。在这之上是苦涩的失望，对自己，对这个时代，和让他变得如此的环境”。他是农民的孩子，大地的孩子，他的血液里流淌着祖祖辈辈千年传承下来的对生活的忍耐力。这是他们共同的道德信仰，“把自己交给这个严苛不公的世界，而那一张张脸毫无表情，铁硬又荒凉”。</p>
<pre><code>“他心怀无法量度的悲伤看着他们最后欢乐的努力，就像生命利用死亡的躯体跳的一场舞蹈。” 这又岂止是斯通纳的悲哀。
</code></pre><h3 id="三"><a href="#三" class="headerlink" title="三."></a>三.</h3><p>​    他知道自己的弱小。他思索过放弃。“他的失落感喷涌而出，彻底将他吞没，他任由这股洪流裹挟着，意志已经失去控制。” 他甚至不想搭救自己，像没有尽头的电梯，直直地一直向下坠啊坠。可他终究无法超越。他知道，那种潜在的力量根植在他的内心，坚定而稳固。</p>
<p>​    年轻的时候，他将这种力量投入到学术中。后来，他又希望将这种力量释放到爱情中，亲情中。</p>
<p>​    我想，他的力量来源于他的自我信仰。</p>
<p>​    《复活》中有这样一段话：“世界上有各种宗教，就因为人都相信别人，不相信自己。有人信旧教，有人信新教，有人信安息会，有人信鞭身教，有人信教堂派，有人信奥地利派，有人信莫罗勘教，有人信阉割派。各种教派都夸自己好。其实他们都像瞎眼的狗崽子一样，在地上乱爬。信仰很多，可是灵魂只有一个。” 比之于那些像戈登一样将自己的信仰托付给毫无意义的毁灭和黑暗力量的年轻人——而恰恰是这些力量推动着世界走向不知名的终点；斯通纳的信仰来源于他自己。</p>
<p>​    他所希望打造改变的是他自己，所希望憧憬的是他自己，想要创造某种可能性的也是他自己。他是理性而坚定的。我想，这也是他和凯瑟琳的婚外恋情最终没有沦为悲剧的原因，他有着清醒的独立认知。无论经历什么，他总是期望着自己进入一种更加有序美好的状态。这种自我信仰，使他没有迷失在平庸的生活中，也使他能够理性乐观地面对人生的千疮百孔。</p>
<p>​    而另一方面，他的自我信仰又是他进行一切斗争的力量源泉。除了保持自我的独立与完整，他的悲悯情怀又推动着他“努力缩回一点小小的距离来怜悯，来爱”。“像在其他危机和绝望时刻一样，他再次把目光投向深植在大学这个机构里的审慎的信仰。他心想那虽然没有多少，但知道这是自己拥有的全部了。”</p>
<p>​    我总觉着，斯通纳就像是现实版的西西弗斯。加缪说</p>
<blockquote>
<p>当荒谬的人开始思考自己的痛苦，他令所有被人膜拜的偶像都哑然失声。</p>
<p>在这个突然间恢复沉寂的世界，对大地声音毫不在乎的无数元素纷纷升起。</p>
<p>来自所有面孔的无意识的、秘密的召唤、诱惑，它们是胜利必然付出的代价，并与之相对。</p>
<p>有阳光就会有阴影，我们必须认识黑夜。</p>
<p>荒谬的人说“好”，然后便会不停地努力。”</p>
<p> “人们总会一次又一次地找回自己的负担。但西西弗斯告诫我们，还有更高的忠实，它可以否定神灵，举起巨石。他最终发现，一切也安好。那座夜色笼罩的山上的每一片矿石，本身都是一个世界。迈向高处的挣扎足够填充一个人的心灵。” 加缪说，人们应当想象西西弗斯是快乐的。</p>
</blockquote>
<p>​    </p>
<p>​    所以，比起“失败”，我也更愿意相信，斯通纳当是一个顶天立地的大写的人。</p>
]]></content>
      <categories>
        <category>Book/Movie/Idea</category>
      </categories>
      <tags>
        <tag>Book</tag>
      </tags>
  </entry>
  <entry>
    <title>Basic Musicianship</title>
    <url>/2019/10/15/Basic%20Musianship/</url>
    <content><![CDATA[<h3 id="Basic-Musicianship"><a href="#Basic-Musicianship" class="headerlink" title="Basic Musicianship"></a>Basic Musicianship</h3><h5 id="Major-Key"><a href="#Major-Key" class="headerlink" title="Major Key"></a>Major Key</h5><p> <img src="https://i.loli.net/2019/10/17/rkY9ZBR4VWmAqEM.png" alt="sharp.png"></p>
<p> <img src="https://i.loli.net/2019/10/17/4iq7grZhGF2AtUL.png" alt="flat.png"></p>
]]></content>
      <categories>
        <category>Art</category>
      </categories>
      <tags>
        <tag>music</tag>
      </tags>
  </entry>
  <entry>
    <title>Basics</title>
    <url>/2019/10/14/Basics/</url>
    <content><![CDATA[<p>Basic settings.<br><a id="more"></a></p>
<h3 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h3><p>cd 到Blog后</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a><br><a href="https://zhangslob.github.io/2017/02/26/%E5%88%A9%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E7%9A%84%E5%8D%9A%E5%AE%A2/" target="_blank" rel="noopener">Markdown</a>   <a href="https://daringfireball.net/projects/markdown/dingus" target="_blank" rel="noopener">在线预览</a>   <a href="https://www.typora.io/" target="_blank" rel="noopener">Typora</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean </span><br><span class="line">$ hexo g -d  <span class="comment">#generate static files and deploy to remote sites</span></span><br><span class="line">$ hexo s  <span class="comment">#server本地静态预览</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a><br>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a><br>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
<h3 id="Change-the-theme"><a href="#Change-the-theme" class="headerlink" title="Change the theme"></a>Change the theme</h3><p>直接在Blog下的config中修改theme</p>
<h3 id="To-Remind"><a href="#To-Remind" class="headerlink" title="To Remind"></a>To Remind</h3><p><a href="https://sm.ms/login" target="_blank" rel="noopener">图床</a></p>
<!--git绑定的是F账号gmail邮箱-->
]]></content>
      <categories>
        <category>Settings</category>
      </categories>
      <tags>
        <tag>setting</tag>
      </tags>
  </entry>
</search>
