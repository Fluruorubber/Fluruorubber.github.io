<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Project,">










<meta name="description" content="This is my final project for SI140(Probability and Mathematical Statistics). I used the jupyter notebook for the writing. The project explores the performance of different multi-armed bandit algorithm">
<meta name="keywords" content="Project">
<meta property="og:type" content="article">
<meta property="og:title" content="Performance of Multi-armed Bandit Algorithms">
<meta property="og:url" content="http://yoursite.com/2020/01/14/Performance-of-Multi-armed-Bandit-Algorithms/index.html">
<meta property="og:site_name" content="--Fluruorubber--">
<meta property="og:description" content="This is my final project for SI140(Probability and Mathematical Statistics). I used the jupyter notebook for the writing. The project explores the performance of different multi-armed bandit algorithm">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://i.loli.net/2019/12/07/NTqe1RVjytgcUu8.png">
<meta property="og:image" content="https://i.loli.net/2019/12/07/meOgqKLtvWhbHrl.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/BtQdJDNVPlZOrwq.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/5uUVwkdMngYNAeC.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/qZObw6FspnDVYr8.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/okhVwWcCJvSDUXE.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/8TEhkbCxUeqDBrn.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/uPl5Zfb7FQBrN4Y.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/I4SUqg1vZyu3oPR.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/AX9hIqKeQiEpxOC.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/bDOpRHTK2fYhxua.png">
<meta property="og:image" content="https://i.loli.net/2019/12/07/xwMdfe7CrQpXG2V.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/1lwMLGtWxE7NX3C.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/HGfat1wgMFrUByE.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/SOJrDXma9koQzB8.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/DV4BN3ISxnYCLXK.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/Nh8JgZ1BsMnX7Lp.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/zjOSpNYCBl1a4T9.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/WRXwVL6qOPGf3aQ.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/qFzJGKCTLocDb5m.png">
<meta property="og:image" content="https://i.loli.net/2019/12/07/F3XxnkmMN87UHD1.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/QIyl51ag29CEKBo.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/mdQtvNkICz26u48.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/IoeMH4fhEQlPqkg.png">
<meta property="og:image" content="https://i.loli.net/2020/02/14/hd1S93Xq84TUBON.png">
<meta property="og:image" content="https://i.loli.net/2019/12/30/Tmkb8DSfuAnMNxH.png">
<meta property="og:updated_time" content="2020-02-15T06:02:32.073Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Performance of Multi-armed Bandit Algorithms">
<meta name="twitter:description" content="This is my final project for SI140(Probability and Mathematical Statistics). I used the jupyter notebook for the writing. The project explores the performance of different multi-armed bandit algorithm">
<meta name="twitter:image" content="https://i.loli.net/2019/12/07/NTqe1RVjytgcUu8.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/01/14/Performance-of-Multi-armed-Bandit-Algorithms/">





  <title>Performance of Multi-armed Bandit Algorithms | --Fluruorubber--</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">--Fluruorubber--</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/14/Performance-of-Multi-armed-Bandit-Algorithms/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Fluruorubber">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="--Fluruorubber--">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Performance of Multi-armed Bandit Algorithms</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-14T19:47:27+08:00">
                2020-01-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Courses/" itemprop="url" rel="index">
                    <span itemprop="name">Courses</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  This is my final project for SI140(Probability and Mathematical Statistics). I used the jupyter notebook for the writing. The project explores the performance of different multi-armed bandit algorithms, which is a classic problem in reinforcement learning.
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><center><font size="6">Performance of Multi-armed Bandit Algorithms</font></center></p>
<h3 id="Basic-Setting"><a href="#Basic-Setting" class="headerlink" title="Basic Setting"></a>Basic Setting</h3><p>&emsp; The multi-armed bandit problem is a classic reinforcement learning problem which indicated the dilemma between the exploitation and exploration.<br>&emsp; We consider a time-slotted bandit system ($t = 0,1,2,\dots$) with three arms. We denote the arm set as $\{1,2,3\}$. Pulling each arm $j$ ($j\in\{1,2,3\}$) will obtain a reward $r_j$, which satisfies a Bernoulli distribution with mean $\theta_j$, </p>
<script type="math/tex; mode=display">
r_j = \begin{cases}1, &w.p. \ \theta_j\\0, &w.p.\ 1-\theta_j,\end{cases}</script><p>where $\theta_j$ are parameters within (0,1) for $j\in\{1,2,3\}$</p>
<p>&emsp; Now we run this bandit system for $N$ ($N$ ≫ 3) time slots. At each time slot $t$, we choose one and only one arm from these three arms, which we denote as $I(t)\in \{1,2,3\}$. Then we pull the arm $I(t)$ and obtain a reward $r_{I(t)}$. Our objective is to find an optimal policy to choose an arm $I(t)$ at each time slot $t$ such that the expectation of the aggregated reward is maximized, $i.e.$, </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t=1,\dots,N}^{}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right].</script><p> If we know the values of $\theta_j, j\in\{1,2,3\}$, this problem is trivial. Since $r_I(t)\sim$ Bern($\theta_{I(t)}$), </p>
<script type="math/tex; mode=display">
\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = \sum\limits_{t=1}^{N}\mathbb{E}\left[r_{I(t)}\right] = \sum\limits_{t=1}^{N}\theta_{I(t)}.</script><p>Let $I(t) = I^* = \text{argmax}\theta_j$ for $t=1,2,\dots, N$, then </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t = 1,\dots, N}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = N\cdot \theta_{I^*}.</script><p> &emsp; However, in reality, we do not know the values of $\theta_j, j\in\{1,2,3\}$. We need to estimate the values $\theta_j$ via empirical samples, and then make the decisions at each time slot. </p>
<h3 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h3><p>&emsp; Suppose we obtain the Bernoulli distribution parameters from an oracle, which are shown in the following table below. Choose $N$ = 10000 and compute the theoretically maximized expectation of aggregate rewards over $N$ time slots. We call it the oracle value. Note that these parameters $\theta_j, j\in\{1,2,3\}$ and oracle values are unknown to the three bandit algorithms. </p>
<p><img src="https://i.loli.net/2019/12/07/NTqe1RVjytgcUu8.png" alt="theta_table.png"></p>
<p>Therefore, we have that </p>
<script type="math/tex; mode=display">
\max\limits_{I(t),t = 1,\dots, N}\mathbb{E}\left[\sum\limits_{t=1}^{N}r_{I(t)}\right] = N\cdot \theta_{I^*} = 1000\times 0.8 = 8000.</script><p>We design three algorithms as follows to maximize the aggregated reward.</p>
<h4 id="epsilon-Greedy-Algorithm"><a href="#epsilon-Greedy-Algorithm" class="headerlink" title="$\epsilon$ - Greedy Algorithm"></a>$\epsilon$ - Greedy Algorithm</h4><p><strong>Main idea:</strong></p>
<p>&emsp; An $\epsilon$ - greedy policy is that simply explores (choose one arm randomly) with probability $\epsilon$ , or otherwise greedily exploits the information we already have and thereby choose the arm with current hightest reward.<br>&emsp; Let $\hat{\theta}(j)$ be the average expectation reward for arm $j$   ($\ j\in\{1,2,3\}\ $). $I(t)\in\{1,2,3\}$ denotes the arm we choose;  $count$$(j)$ is the number of how many times arm $j$ has been chosen.<br>&emsp; Therefore, for each time slots (we have N in total), we decide the arm $I(t)$ by explorarion or exploitation. After that, $count$($I(t)$) increases by 1.  Suppose that arm $I(t)$ has been picked for $n$ times and results in reward $x_1,x_2,\dots,x_n$, $count(I(t)) = n+1$.</p>
<script type="math/tex; mode=display">
\begin{aligned}\hat{\theta}_n &= \frac{x_1+\dots+x_n}{n}\\ \hat{\theta}_{n+1} &= \frac{x_1+\dots+x_n+x_{n+1}}{n+1} = \frac{n\hat{\theta}_n+x_{n+1}}{n+1}= \hat{\theta}_n+\frac{1}{count(I(t))}(r_{I(t)}-\hat{\theta}_n) \end{aligned}</script><p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/meOgqKLtvWhbHrl.png" alt="Greedy_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results</strong><br>&emsp; We compute the expectation, and plot the actual reward and average reward against time slot ($t=1,2,\dots,N$). Due to the large scale of $N$, to see more clearly, we set the $x$ axis to be the $\lg N$.<br>&emsp; To see the exact performance of each earm, we also plot the the reward of each arm. If the arm is not chosen, we set the reward to be -1 as a default assignment. Each time when a arm is chosen, we alternate the default reward ($-1$) with the actual reward ( $0$ or $1$ ).<br>&emsp; To reduce the experiment error, we repeat the experiment for $100$ times and take the average values as outputs.<br>&emsp; Here are the code and results.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="comment"># #initialize</span></span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">    result = []</span><br><span class="line">    eposilong = eval(input(<span class="string">"epsilon:"</span>))</span><br><span class="line">    temp = [];temp2 = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        reward = [];avg = []</span><br><span class="line">        r = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; amr1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">            choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">                index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][t])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r[index][t]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                amr1[t] = r[index][t]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r[index][t]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward); temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(amr1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig1= plt.figure()</span><br><span class="line">    plt.title(<span class="string">"Epsilon-Greedy"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"mediumseagreen"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.sca(fig2)</span></span><br><span class="line">    fig2 = plt.figure()</span><br><span class="line">    plt.title(<span class="string">"Epsilon-Greedy"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>epsilon:0.1
mean= 7787.06
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/BtQdJDNVPlZOrwq.png">
    <img src="https://i.loli.net/2020/02/14/5uUVwkdMngYNAeC.png">
</figure>




<pre><code>epsilon:0.5
mean= 7002.36
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/qZObw6FspnDVYr8.png">
    <img src="https://i.loli.net/2020/02/14/okhVwWcCJvSDUXE.png">
</figure>




<pre><code>epsilon:0.9
mean= 6199.36
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/8TEhkbCxUeqDBrn.png">
    <img src="https://i.loli.net/2020/02/14/uPl5Zfb7FQBrN4Y.png">
</figure>



<p>According to the simulation, we observe that:</p>
<ul>
<li>$\epsilon$ denotes the probability of exploration. Therefore, when $\epsilon = 0.1$, the average reward almost converges to 0.8 (but still not reach 0.8, because we always has $\epsilon$ probability to explore), the actual reward almost oscillates near 0.8. We also see that as time goes by, we are more likely to choose arm 3 and only choose arm 1 or 2 in the exploration phase. </li>
<li>Compared to $\epsilon = 0.1$, when $\epsilon$ is higher, we get worse aggregated expectation. Because when it comes to large time slot, we already know that the third arm deliver the best performance. If $\epsilon$ is still high and if we are still exploring, it would drag down the aggregated reward. Additionally, if $\epsilon$ is too high, we only have small probability to exploit arm3 as shown in the figure.</li>
</ul>
<p>However, is it always the case that — when $\epsilon$ increases, we get worse performance? We set $\epsilon = 0.005, 0.01, 0.1,  0.3, 0.5, 0.75$, set $N=1500$ and do the simulation again.<br>Here are the code the result.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">1500</span></span><br><span class="line">e = [<span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.1</span>,<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.75</span>]</span><br><span class="line">c = [<span class="string">"#fe4365"</span>,<span class="string">"#3b8686"</span>,<span class="string">"#6a60a9"</span>,<span class="string">"#f9a11b"</span>,<span class="string">"#03a6ff"</span>]</span><br><span class="line">style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">    x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">    eposilong = e[o_]</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    r = []</span><br><span class="line">    HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">    count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    exp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">        choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">            index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">        count_j[index] += <span class="number">1</span></span><br><span class="line">        HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">        reward.append(r[index][t])</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">            exp += <span class="number">1</span></span><br><span class="line">        avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">    plt.plot(list(range(N)),avg,color =c[o_],label=e[o_],linewidth = <span class="number">1</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/02/14/I4SUqg1vZyu3oPR.png" alt="png"></p>
<p>$\ \ \ $We notice that if $\epsilon$ is too small, we do too little exploration, therefore, we may not get an accurate understanding of the arm performance. Therefore, the total reward is decreased.</p>
<h4 id="Improvement-of-epsilon-Greedy-Algorithm"><a href="#Improvement-of-epsilon-Greedy-Algorithm" class="headerlink" title="Improvement of $\epsilon$-Greedy Algorithm"></a>Improvement of $\epsilon$-Greedy Algorithm</h4><p>$\ \ \ $We design an improved $\epsilon$-Greedy algorithm to get better performance. The motivation is that — when $t$ is small, we set large $\epsilon$ to explore and obtain information quickly; when $t$ is large, we set small $\epsilon$ and exploit the information we already have. Shown as the follows, we set $\epsilon = t^{-\frac{1}{2}}$. We remain the $N=10000$ and repeat the experiments for 100 times just as previous experiments.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">10000</span></span><br><span class="line">theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]  </span><br><span class="line">result = []</span><br><span class="line">eposilong = <span class="number">0.0</span></span><br><span class="line">temp = []</span><br><span class="line">temp2 = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    r = []</span><br><span class="line">    HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">    count_j = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    exp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        r.append(list(bernoulli.rvs(size = N, p = theta_j[i])))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(N):</span><br><span class="line">        eposilong = <span class="number">1</span>/((t+<span class="number">1</span>)**(<span class="number">1</span>/<span class="number">2</span>))   <span class="comment">####This is the improvement.</span></span><br><span class="line">        choice = int(bernoulli.rvs(size = <span class="number">1</span>,p = eposilong))  <span class="comment">#indicator of whether exploitation or not</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>  == choice:</span><br><span class="line">            index = random.randint(<span class="number">0</span>,<span class="number">2</span>)   <span class="comment">#index: I(t)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = HTHETA_J.index(max(HTHETA_J[<span class="number">2</span>],HTHETA_J[<span class="number">1</span>],HTHETA_J[<span class="number">0</span>]))</span><br><span class="line">        count_j[index] += <span class="number">1</span></span><br><span class="line">        HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/count_j[index]*(r[index][t]- HTHETA_J[index])</span><br><span class="line">        reward.append(r[index][t])</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span>==r[index][t]:</span><br><span class="line">            exp += <span class="number">1</span></span><br><span class="line">        avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">    result.append(exp)</span><br><span class="line">    temp.append(reward) </span><br><span class="line">    temp2.append(avg)</span><br><span class="line"></span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">ax.hist(result, color = <span class="string">"#58c49f"</span>, bins=<span class="number">20</span>, edgecolor = <span class="string">"darkslategrey"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Expectation"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line">plt.title(<span class="string">"Improved Epsilon-Greedy"</span>)</span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">plt.xlabel(<span class="string">'log(N)'</span>)</span><br><span class="line">plt.plot(x,reward,color = <span class="string">"seagreen"</span>, label=<span class="string">"reward"</span>)</span><br><span class="line">plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>mean= 7956.26
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/AX9hIqKeQiEpxOC.png">
        <img src="https://i.loli.net/2020/02/14/bDOpRHTK2fYhxua.png">
</figure>



<p>As a result, we discovery that the new aggregated reward is much closer to 8000; the reward and average reward converge to 0.8 more quickly.</p>
<h4 id="Upper-Confidence-Bound-UCB-Algorithm"><a href="#Upper-Confidence-Bound-UCB-Algorithm" class="headerlink" title="Upper Confidence Bound (UCB) Algorithm"></a>Upper Confidence Bound (UCB) Algorithm</h4><p><strong>Main idea:</strong></p>
<p>$\ \ \ $First, we pull each arm once for initialization.</p>
<p>$\ \ \ $For $t = 4,\dots, N$, we choose the arm with highest Upper Confidence Bound (UCB).</p>
<script type="math/tex; mode=display">
I(t) \leftarrow \text{argmax}\left(\hat{\theta}(j)+c\cdot\sqrt{\frac{2\ln t}{count(j)}}\right)</script><p>where $\hat{\theta}(j)$ is the average reward observed from arm $j$ , $c$ is a constanst, $t$ is the number of attempts so far, $count(j)$ is the number of times arm $j$ has been pulled. In this formula, the first part is the exploitation term and the second part is the exploration term.</p>
<p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/xwMdfe7CrQpXG2V.png" alt="UCB_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    result = []</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>] </span><br><span class="line">    temp = [];temp2 = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    c = eval(input(<span class="string">"c:"</span>))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):   <span class="comment">###in total 100 repeats</span></span><br><span class="line">        <span class="comment">##initialize</span></span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        reward = []; avg = []</span><br><span class="line">        r = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; arm1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        count_j = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        argm = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = <span class="number">1</span>, p = theta_j[i])))</span><br><span class="line">            HTHETA_J[i] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==i:</span><br><span class="line">                arm0[<span class="number">0</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==i:</span><br><span class="line">                arm1[<span class="number">1</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[<span class="number">2</span>] = r[i][<span class="number">0</span>]</span><br><span class="line">        reward = [r[<span class="number">0</span>][<span class="number">0</span>],r[<span class="number">1</span>][<span class="number">0</span>],r[<span class="number">2</span>][<span class="number">0</span>]]</span><br><span class="line">        r[<span class="number">0</span>] = r[<span class="number">0</span>]+[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        r[<span class="number">1</span>] = [<span class="number">0</span>] + r[<span class="number">1</span>] + [<span class="number">0</span>]</span><br><span class="line">        r[<span class="number">2</span>] = [<span class="number">0</span>,<span class="number">0</span>]+r[<span class="number">2</span>]</span><br><span class="line">        avg = [reward[<span class="number">0</span>]/<span class="number">1</span>,(reward[<span class="number">0</span>]+reward[<span class="number">1</span>])/<span class="number">2</span>,(reward[<span class="number">0</span>]+reward[<span class="number">1</span>]+reward[<span class="number">2</span>])/<span class="number">3</span>]</span><br><span class="line">          </span><br><span class="line">        <span class="comment">##UCB</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">3</span>,N):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                argm[j] = HTHETA_J[j] + c*math.sqrt(<span class="number">2</span>*math.log(t)/count_j[j])</span><br><span class="line">                r[j].append(int(bernoulli.rvs(size = <span class="number">1</span>,p = theta_j[j])))</span><br><span class="line">            index = argm.index(max(argm[<span class="number">0</span>],argm[<span class="number">1</span>],argm[<span class="number">2</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/(count_j[index])*(r[index][<span class="number">-1</span>]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r[index][<span class="number">-1</span>]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                arm1[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r[index][<span class="number">-1</span>]</span><br><span class="line">            avg.append(exp/t)</span><br><span class="line">    </span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward); temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(arm1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    fig1= plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"orange"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    fig2 = plt.subplots()</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>c:1
mean= 7892.49
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/1lwMLGtWxE7NX3C.png">
        <img src="https://i.loli.net/2020/02/14/HGfat1wgMFrUByE.png">
</figure>




<pre><code>c:5
mean= 7148.43
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/SOJrDXma9koQzB8.png">
        <img src="https://i.loli.net/2020/02/14/DV4BN3ISxnYCLXK.png">
</figure>




<pre><code>c:10
mean= 6676.07
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/Nh8JgZ1BsMnX7Lp.png">
        <img src="https://i.loli.net/2020/02/14/zjOSpNYCBl1a4T9.png">
</figure>




<p>According to the simulation:</p>
<ul>
<li>Each time the best arm is selected, $\hat{\theta}(j)$ would increase, however, $count(j)$ also increases and cause the second term to decrease. On the other hand, each time an action other than arm $j$ is selected, $t$ increases and the whole term increase, which cause the arm more likely to be choosen next time. </li>
<li>The first term indicates the exploitation phase, and the second term indicates the exploration phase. Very silimar to the $\epsilon$ - Greedy Algorithm, if we set $c$ to be larger, then we do more exploration even $t$ is relatively large, and it would be very difficlut for the figure to converge to 0.8.</li>
</ul>
<h4 id="Improvement-of-UCB-Algorithm"><a href="#Improvement-of-UCB-Algorithm" class="headerlink" title="Improvement of UCB Algorithm"></a>Improvement of UCB Algorithm</h4><p>$\ \ \ $We design an improved UCB algorithm to get better performance. The motivation is that — when $t$ is small, we set large $c$ to explore and obtain information quickly; when $t$ is large, we set small $c$ and exploit the information we already have. Shown as the follows, we set $c = \frac{1}{\log(t)}$. We remain the $N=10000$ and repeat the experiments for 100 times just as previous experiments.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> o_ <span class="keyword">in</span> range(<span class="number">1</span>):</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    result = []</span><br><span class="line">    theta_j = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>] </span><br><span class="line">    result = [] </span><br><span class="line">    temp = []</span><br><span class="line">    temp2 = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):   <span class="comment">###in total 100 repeats</span></span><br><span class="line">        <span class="comment">##initialize</span></span><br><span class="line">        exp = <span class="number">0</span></span><br><span class="line">        avg = []</span><br><span class="line">        r = []</span><br><span class="line">        count_j = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">        HTHETA_J = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">        argm = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            r.append(list(bernoulli.rvs(size = <span class="number">1</span>, p = theta_j[i])))</span><br><span class="line">            HTHETA_J[i] = r[i][<span class="number">0</span>]</span><br><span class="line">        reward = [r[<span class="number">0</span>][<span class="number">0</span>],r[<span class="number">1</span>][<span class="number">0</span>],r[<span class="number">2</span>][<span class="number">0</span>]]</span><br><span class="line">        avg = [reward[<span class="number">0</span>]/<span class="number">1</span>,reward[<span class="number">1</span>]/<span class="number">2</span>,reward[<span class="number">2</span>]/<span class="number">3</span>]</span><br><span class="line">          </span><br><span class="line">        <span class="comment">##UCB</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">4</span>,N+<span class="number">1</span>):</span><br><span class="line">            c = <span class="number">2</span>/(math.log(t))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                argm[j] = HTHETA_J[j] + c*math.sqrt(<span class="number">2</span>*math.log(t)/count_j[j])</span><br><span class="line">                r[j].append(int(bernoulli.rvs(size = <span class="number">1</span>,p = theta_j[j])))</span><br><span class="line">            index = argm.index(max(argm[<span class="number">0</span>],argm[<span class="number">1</span>],argm[<span class="number">2</span>]))</span><br><span class="line">            count_j[index] += <span class="number">1</span></span><br><span class="line">            HTHETA_J[index] = HTHETA_J[index] + <span class="number">1</span>/(count_j[index])*(r[index][<span class="number">-1</span>]- HTHETA_J[index])</span><br><span class="line">            reward.append(r[index][<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r[index][<span class="number">-1</span>]:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            avg.append(exp/t)</span><br><span class="line">    </span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward) </span><br><span class="line">        temp2.append(avg)</span><br><span class="line">    reward = []</span><br><span class="line">    avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.hist(result, color = <span class="string">"wheat"</span>, edgecolor = <span class="string">"orange"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"Expectation"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line">    plt.title(<span class="string">"UCB"</span>)</span><br><span class="line">    <span class="comment">#plot the reward and average reward</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig,ax = plt.subplots()</span><br><span class="line">    plt.xlabel(<span class="string">'log(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"lightsalmon"</span>, label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>mean= 7965.27
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/WRXwVL6qOPGf3aQ.png">
        <img src="https://i.loli.net/2020/02/14/qFzJGKCTLocDb5m.png">
</figure>


<p>&emsp; On average, we get better performance.<br>&emsp; However, we also notice that, for some cases, the total reward is relatively small, the UCB algorithm is quite unstable and do not have a excellent lower bound.</p>
<h4 id="Thompson-Sampling-Algorithm"><a href="#Thompson-Sampling-Algorithm" class="headerlink" title="Thompson Sampling Algorithm"></a>Thompson Sampling Algorithm</h4><p><strong>Main idea:</strong><br>&emsp; We notice that in the UCB algorithm, we actually do not use the information of probability distribution.<br>&emsp; The next algorithm, however, we take full advantage of the information that each arm generates a Bernoulli distributed reward.<br>&emsp; In Thompson Sampling algorithm, we define a prior probability distribution for each arm, $\hat{\theta}(j)\sim\text{Beta}(\alpha_j,\beta_j)$. In the experiment, for arm $j$, if we observe there are $k$ success out of $m$ attempts, then we update the probability, i.e., $\hat{\theta}(j)\sim\text{Beta}(\alpha_j+k, \beta_j+n-k)$.<br>&emsp; The proof is shown as follows.</p>
<script type="math/tex; mode=display">
\text{Def: $X$ is the number of success.}\\
\begin{align*}
    \Theta&\sim\text{Beta}(\alpha,\beta), X|\theta\sim\text{Bin}(n,\theta)\\
    f_{\Theta}(\theta|X=k)&=\frac{P(X=k|\theta)\cdot f(\theta)}{P(X=k)} \\
    &=\frac{\binom{n}{k}\theta^k(1-\theta)^{n-k}\frac{1}{\beta(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_{0}^{1}P(X=k|\theta)f(\theta) d\theta}\\
    &=C\cdot \theta^{\alpha+k-1}(1-\theta)^{n-k+\beta-1}\\
    &\sim\text{Beta}(\alpha+k,n-k+\beta)
\end{align*}</script><p>&emsp; In the simulation, we first pull each arm once as initialization. For $t = 4,\dots, N$, we always pull the arm with highest $\hat{\theta}$.</p>
<p><strong>Pseudocode:</strong><br><img src="https://i.loli.net/2019/12/07/F3XxnkmMN87UHD1.png" alt="TS_psedo.png" style="zoom:80%;"></p>
<p><strong>Code and Results:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> beta</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"></span><br><span class="line">N = <span class="number">10000</span></span><br><span class="line">theta = [<span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>]</span><br><span class="line"><span class="keyword">for</span> oo <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    <span class="comment">#initialize</span></span><br><span class="line">    result = [] </span><br><span class="line">    temp = []; temp2 = []</span><br><span class="line">    a = []; b = []</span><br><span class="line">    a0=[]; a1=[]; a2=[]</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha1 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta1 = "</span>)))</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha2 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta2 = "</span>)))</span><br><span class="line">    a.append(eval(input(<span class="string">"alpha3 = "</span>)))</span><br><span class="line">    b.append(eval(input(<span class="string">"beta3 = "</span>)))</span><br><span class="line">    <span class="keyword">for</span> o <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        exp = <span class="number">0</span>; aa=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]; bb=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">            aa[i] = a[i]; bb[i] = b[i]</span><br><span class="line">        reward = []; avg = []</span><br><span class="line">        arm0 = [<span class="number">-1</span>]*N; arm1 = [<span class="number">-1</span>]*N; arm2 = [<span class="number">-1</span>]*N</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> range(N):  <span class="comment">##对每一个time slot</span></span><br><span class="line">            HTHETA_j = []</span><br><span class="line">            <span class="comment">#sample model</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                HTHETA_j.append(float(beta.rvs(aa[j],bb[j],size = <span class="number">1</span>)))</span><br><span class="line">            index = HTHETA_j.index(max(HTHETA_j[<span class="number">0</span>],HTHETA_j[<span class="number">1</span>],HTHETA_j[<span class="number">2</span>]))</span><br><span class="line">            r = int(bernoulli.rvs(size = <span class="number">1</span>,p = theta[index]))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">1</span> == r:</span><br><span class="line">                exp += <span class="number">1</span></span><br><span class="line">            reward.append(r)</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>==index:</span><br><span class="line">                arm0[t] = r</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">1</span>==index:</span><br><span class="line">                arm1[t] = r</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                arm2[t] = r</span><br><span class="line">            avg.append(exp/(t+<span class="number">1</span>))</span><br><span class="line">            aa[index] = aa[index] + r;bb[index] = bb[index] + <span class="number">1</span>-r</span><br><span class="line">        result.append(exp)</span><br><span class="line">        temp.append(reward);temp2.append(avg)</span><br><span class="line">        a0.append(arm0); a1.append(arm1); a2.append(arm2)</span><br><span class="line"></span><br><span class="line">    reward = []; avg = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp)):</span><br><span class="line">            t += temp[j][i]</span><br><span class="line">        reward.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(temp2)):</span><br><span class="line">            t += temp2[j][i]</span><br><span class="line">        avg.append(t/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    arm0=[]; amr1=[]; arm2=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        t0=<span class="number">0</span>; t1=<span class="number">0</span>; t2=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            t0 += a0[j][i]; t1 += a1[j][i]; t2 += a2[j][i]</span><br><span class="line">        arm0.append(t0/<span class="number">100</span>); amr1.append(t1/<span class="number">100</span>); arm2.append(t2/<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"mean="</span>,np.mean(result))</span><br><span class="line">    style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list(range(N)):</span><br><span class="line">        x.append(math.log10(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    fig1= plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"Thompson Sampling"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,reward,color = <span class="string">"#A593E0"</span>,label=<span class="string">"reward"</span>)</span><br><span class="line">    plt.plot(x,avg,color = <span class="string">"grey"</span>,label=<span class="string">"average reward"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.sca(fig2)</span></span><br><span class="line">    fig2 = plt.subplots()</span><br><span class="line">    plt.title(<span class="string">"Thompson Sampling"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'lg(N)'</span>)</span><br><span class="line">    plt.plot(x,arm0, color = <span class="string">"#df405a"</span>, label = <span class="string">"arm1"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,amr1, color = <span class="string">"#3b8686"</span>,label = <span class="string">"arm2"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.plot(x,arm2, color = <span class="string">"#0080ff"</span>, label = <span class="string">"arm3"</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>alpha1 = 1
beta1 = 1
alpha2 = 1
beta2 = 1
alpha3 = 1
beta3 = 1
mean= 7988.33
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/QIyl51ag29CEKBo.png">
        <img src="https://i.loli.net/2020/02/14/mdQtvNkICz26u48.png">
</figure>


<pre><code>alpha1 = 2
beta1 = 4
alpha2 = 3
beta2 = 6
alpha3 = 1
beta3 = 2
mean= 7988.64
</code></pre><figure class="half">
    <img src="https://i.loli.net/2020/02/14/IoeMH4fhEQlPqkg.png">
        <img src="https://i.loli.net/2020/02/14/hd1S93Xq84TUBON.png">
</figure>


<p>According to the simulation: </p>
<ul>
<li>Different from $\epsilon$ - Greedy and UCB algorithm, as $t\rightarrow \infty$, the probability of chosen arm 1 and arm 2 almost converge to 0.</li>
<li>We notice that the prior distribution only makes small difference to the final reward. However, if the prior probability is more closer to the true probability, it would take less time to find out which arm is the best.</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>The overall reults is shown as follows:<br><img src="https://i.loli.net/2019/12/30/Tmkb8DSfuAnMNxH.png" alt="a.png" style="zoom:80%;"></p>
<h3 id="Dependent-Cases"><a href="#Dependent-Cases" class="headerlink" title="Dependent Cases"></a>Dependent Cases</h3><p>&emsp; In the previous situation, we assume the reward distribution of three arms are independent. Here, we provide a method to analyze the dependent multi-armed bandit problems.</p>
<h4 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h4><p>&emsp; To generalize the problem, we assume that there is a machine with $N$ arms that are grouped into $K$ clusters. Every arm in a single cluster are dependent, but arms in different clusters are independent of each other. Each arm $i$ has a fixed but unknown probability $\theta(i)$ of generating a success reward (i.e. $r_i = 1$). Let $[i]$ denotes the whole arm cluster which contains the $i$th arm, and define $C_{[i]}$ be the set of all arms in that cluster including the $i$th arm.<br>&emsp; Define $s_i(t)$ be the number of times arm $j$ successfully generates a reward in $t$ time slot, $f_i(t)$ be the number of times that arm $i$ fails to generate a reward, $\varphi(h_{[i]})$ be the prior probability distribution and function $h_{[i]}$ abstract out the dependence of arms on each other in one cluster.<br>&emsp; Therefore, we have that </p>
<script type="math/tex; mode=display">
\begin{align*}s_i(t)|\theta(i)&\sim |\text{ Bin}(s_i(t)+f_i(t), \theta_i)\\ \theta_i&\sim \varphi(h_{[i]})\end{align*}</script><p>&emsp; In each timeslot, we solve the problem in two steps:</p>
<pre><code>1. Selection step: Apply a specific policy to choose the arm to pull.
2. Update step: Use the result of the arm pull to update the information.
</code></pre><p>&emsp; We should notice the difference between independent and the dependent cases. In a independent situation, once arm $j$ is pulled, only the information of arm $i$ is updated. However, in the dependent cases, once an arm $i$ is chosen, the state of all arms in $C_{[i]}$ is changed.</p>
<h4 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h4><p>&emsp; In each time slot, for each cluster $i$, we computer the reward estimate $\hat{\theta}(i)$ and the corresponding estimate variance $\hat{\sigma}(i)$ of  each cluster. After that, we use a specfic policy (such as UCB, Thompson Sampling, etc.) to select a cluster. Finally, we use the policy to choose the “best” arm in that cluster. In this method, a good estimate reward should be accurate and converge quickly (i.e., $\hat{\sigma}(j)\to 0$ quickly).<br>&emsp;We have two strategies shown as follows. </p>
<ul>
<li>Mean Strategy:<ul>
<li>For all arm $j$ in cluster $C_j$, according to the Binomial distribution, we set the cluster characteristics as follows:<script type="math/tex; mode=display">
\begin{align*}\hat{\theta}(j) &= \frac{s_j}{s_j+f_j}\\\hat{\sigma}(j) &= (s_j+f_j)\hat{\theta}(j)(1-\hat{\theta}(j))\end{align*}</script>Here, the $s_j, f_j$ are posterior values.</li>
<li>However, we notice that in the mean strategy, if there is one “bad” arm in a cluster, then the total estimate reward is dragged down. Therefore, it might be difficult to find the best rewarded arm if its siblings perform terribly. So, we design another algorithm shown as follows.</li>
</ul>
</li>
<li>Max Strategy:<ul>
<li>In this strategy, each cluster is represented by the arm that is currently best in it. That is:<script type="math/tex; mode=display">
\begin{align*}\hat{\theta}(j) &= max_{i\in C_j}\{\hat{\theta}(i)\}\\\hat{\sigma}(j) &= \text{corresponding }\hat{\sigma}(i)\end{align*}</script></li>
<li>Compared to the mean strategy, this method would be closer to maximum success probability of cluster $j$. Because $\hat{\theta}(j)$ is not dragged down by its families.</li>
<li>However, this method neglects all observations of other arms in that cluster and does not take full advantage of all current information. </li>
</ul>
</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li>Slivkins, A. (2019). Introduction to multi-armed bandits. <em>Foundations and Trends in Machine Learning</em>. <a href="https://doi.org/10.1561/2200000068" target="_blank" rel="noopener">https://doi.org/10.1561/2200000068</a></li>
<li>Pandey, Sandeep &amp; Chakrabarti, Deepayan &amp; Agarwal, Deepak. (2007). Multi-armed bandit problems with dependent arms.. 721-728. </li>
<li>Connor Lee, Hoang Le, R. M. (2016). Multi-armed Bandits. Retrieved from <a href="http://www.yisongyue.com/courses/cs159/" target="_blank" rel="noopener">http://www.yisongyue.com/courses/cs159/</a></li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Project/" rel="tag"># Project</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/01/13/Introduction to Life Science/" rel="next" title="Introduction to Life Science">
                <i class="fa fa-chevron-left"></i> Introduction to Life Science
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/02/03/2019-nCov/" rel="prev" title="2019-nCov">
                2019-nCov <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Fluruorubber">
            
              <p class="site-author-name" itemprop="name">Fluruorubber</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Basic-Setting"><span class="nav-number">1.</span> <span class="nav-text">Basic Setting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Simulation"><span class="nav-number">2.</span> <span class="nav-text">Simulation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#epsilon-Greedy-Algorithm"><span class="nav-number">2.1.</span> <span class="nav-text">$\epsilon$ - Greedy Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Improvement-of-epsilon-Greedy-Algorithm"><span class="nav-number">2.2.</span> <span class="nav-text">Improvement of $\epsilon$-Greedy Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Upper-Confidence-Bound-UCB-Algorithm"><span class="nav-number">2.3.</span> <span class="nav-text">Upper Confidence Bound (UCB) Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Improvement-of-UCB-Algorithm"><span class="nav-number">2.4.</span> <span class="nav-text">Improvement of UCB Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Thompson-Sampling-Algorithm"><span class="nav-number">2.5.</span> <span class="nav-text">Thompson Sampling Algorithm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary"><span class="nav-number">3.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dependent-Cases"><span class="nav-number">4.</span> <span class="nav-text">Dependent Cases</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Models"><span class="nav-number">4.1.</span> <span class="nav-text">Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Method"><span class="nav-number">4.2.</span> <span class="nav-text">Method</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fluruorubber</span>

  
</div>






  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
